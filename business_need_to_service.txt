
Test # 1
----------

Inter-region VPC access- AWS Direct Connect Gateway
Cache and distribute high resolution images and other static assets of the website - Cloud Front
Security Rules that block common attack patterns - AWS WAF
Apply Patches to Windows EC2 Instances - Associate the predefined AWS-DefaultPatchBaseline
Custom Built Solution For User Authentication - 
	- OpenID Connect Compatible Solution
	- SAML-compatible solution to handle authentication and authorization
Use IAM roles for granting user permission to AWS resources - Amazon Cognito Identity Pools
	- Use LDAP for user authentication and use SAML assertion to perform authorization to IAM 		identity provider
Centrally manage policies across multilple AWS accounts by allowing or denying particular AWS services for individual accounts or for group of accounts - Use AWS Organizations and Service Control Policies to control list of services to be used by each member account
Servers located in different VPCs need to connect to a central VPC - Link VPC to central VPC using VPC peering
Highly available database - Use read-replicas in another availability zone
EBS volumes are not enough to store growing data - Use s3
Search 50 TB of on-premises data - Integrate file system of local data center to AWS Storage Gateway by setting up file gateway appliance on-premises
Facial Recognition - Amazon Rekognition
Central database server that can be accessed from other VPCs - Private hosted zone with domain name of database, specify VPCs that you want to associate with hosted zone
Logging solution to track all changes made in all regions - AWS CloudTrail trail, using --is-multi-region-trail
Deploy new application stack without impacting existing users - Shift traffic between existing and new stack using Blue/Green deployment strategy
Prevent SQL Injection attacks - Use AWS WAF to add a web access control list (ACL)
Domain registeration - Amazon Route53
Encrypt database credentials in rest and transit - Upload the database credentials with a Secure String data type in AWS Systems Manager Parameter store
Handle peak demand of 300,000 users - Auto-scaling group of Amazon Ec2 instances spanning multiple availability zones behind an Application Load Balancer
Allow users to store photos with captions - Cognito for user authentication and management. DynamoDB table to store user data. S3 bucket to store user photos. Distribute static content using CloudFront
Protect customers from common man in middle attacks (DNS Spoofing, HTTPS Spoofing, SSL Hijacking) - Enable DNSSEC validation for all public hosted zones (prevent DNS request tampering). Use AWS Certificate Manager (ACM) to generate a valid TLS/SSL certificate for domain name. Configure Application load balancer with HTTPS listener to use ACM SSL/TLS certificate
Provide 500 GB worth of static dataset made available to EC2 instances upon bootup - Mount Amazon EFS volume containing the static dataset on instances upon bootup
Data storage and retreival, Storage requirement of 10-15 TB, millions of records - DynamoDb table. TTL setting to delete records after x days
Search through scanned images - Cloud search for query processing, Amazon Texaract for detecting and recognizing text from scanned old newspapers. s3 bucket to store and server scanned image files
Secure database credentials passed to docker image running on ECS Fargate - Store database credentials using AWS Secrets Manager, encrypt them using AWS KMS. Allow ECS IAM role access to both KMS and AWS Secrets Manager. Specify secrets with the name of environment variable to set in container
Collect and analyze logs from 200 EC2 instances - Unified CloudWatch Logs agent on each on-demand EC2 instance. Analyze log data with CloudWatch log insights
Heterogenous database migration, transform on-premises Oracle Database to PostgreSQL, schema and code transformation required first - AWS Schema Conversion tool to convert source schema to match that of target database. Migrate database using AWS Database migration service
Allow private DNS to be shared among virtual private clouds (VPCs) in different AWS accounts - Setup shared services VPC on your central account, VPC peering of other VPCs. On Amazon Route53 create private hosted zone associated with shared VPC. Associate VPCs from other accounts with this hosted zone
Security of SSL private key, Application logs to be stored securely and durably - Use CloudHSM deployed on two availability zones to perform SSL transactions and deliver your application logs to private S3 bucket using server-side encryption
Migrate virtual machines from on-premises data center to AWS - 

Allow frequent access to company documents for first three months, rarely after that Documents to be retained for atleast 5 years - Create bucket lifecycle policy that will move documents to Amazon S3 Glacier after three months and will delete objects older than 5 years
Distributed denial of service (DDoS) attacks - Integrate AWS WAF and ALB, Use Amazon CloudFront distribution for both static and dynamic content
Mobile user preference data, for 3 million regular customers - Provision a table in DynamoDB
System to automatically discover, classify and protect any personally identifiable information - Use Amazon Macie to automatically discover, classify and protect your sensitive data
60 TB of raw data to be transfered from On-premise Oracle data warehouse to Amazon Redshift - Request Snowball edge device, use AWS Schema conversion tool to process on-premises data warehouse and load it to snowball edge device. Once snowball edge imports data to s3, use AWS SCT to migrate the data to Amazon Redshift
Generate database reports for very large number of users - Generate reports from MySQL database in Multi-AZ RDS deployment configurations with Read Replicas
Serve around 10 million queries in a day - Launch a CloudFront distribution to cache content with a TTL set to expire objects daily
Company accounts managed using AWS organization - 
An automated solution that will scan code commit repositories for committed IAM credentials - Custom lambda triggeed on CodeCommit push events, if credentials found, user notified and IAM keys disabled
Provide access to Amazon DynamoDB to store caption for mobile users - Create an IAM role for the Web Identity Provider, and setup permissions for the IAM role to allow GET and PUT operations in Amazon S3 and DynamoDB
Scalable Call-Center system using AWS - Amazon Connect Service
Allow call center callers to perform tasks without having them to speak to call center agent - Create a conversational chatbot using Amazon Lex with automatic speech recognition and natural language understanding to recognize the intent of callers
Allow call center app to query other business apps - Use AWS Lambda functions
Containerized microservice hosted on ECS, to follow security best practise of least privilege - Use the awsvpc network mode in task definition, Attach security groups to ECS tasks and use IAM roles for tasks to access other resources
Stop sharing reserved instance discounts with other AWS accounts - Turn off Reserved instance sharing on master account
Latest security patches to be installed on EC2 instances - Setup a patch baseline that defines which patches are approved for installation on your instances, using AWS System Manager Patch Manager
A system that checks, all EC2 instances are using approved AMIs - Use AWS config managed rule which automatically checks whether you are running Ec2 instances, using approved AMIs
Process several petabytes of images - Utilize AWS batch with managed compute environments to create a fleet using spot instances
A reliable and durable logging solution to track changes made to all of your EC2, IAM and RDS resources in all of AWS regions - Create a new trail in AWS CloudTrail with global services option selected, store logs in s3 bucket, Create IAM roles, S3 bucket policies, and enable MFA delete on the s3 bucket storing logs
Setup a monitoring system to notify solution architect, for any changes to company AWS accounts (for e.g., third-party AWS account added to AWS Organization) - Create a trail in Amazon CloudTrail to capture all API calls to your AWS Organizations. Use Amazon Event Bridge and SNS to raise events when administrator specified actions occur in your organization
Encrypt credit card numbers, and pass the PCI DSS compliance test - Configure CloudFront distribution to enforce secure end-to-end connections to origin servers by using HTTPS and field level encryption. Configure your origin to add a Cache-Control max-age directive to your objects, specify longest practical-value for max-age to increase your cache hit ratio
Copy information to or from shared resources from another AWS account - Setup cross-acount access with a resource-based policy
Continously audit policy configurations - Use AWS Config rules to periodically audit changes to the IAM policy and monitor the compliance of configuration
Make application fault tolerant to problems in any Region, Application tier must be resilient in any region - Create a geo-location routing policy on Amazon Route53 to point global users to designated regions, Combine this with failover answer routing policy with health checks to direct users to a healthy region at any given time. Deploy the application tier on an AutoScaling group of EC2 instnaces for each region in active-active configuration
Accept and process biometric data from IoT devices, as well as provide complete trends and health reports - Use Amazon kinesis streams to collect incoming biometric data
Provide solution that would have both on-premises and Fargate managed in same cluster - Utilize Amazon ECS Anywhere to stream-line software management on-premises and on AWS with standard container orchestrator
Transactions made in one region to be repliacted to other regions - Create Global DynamoDB table with replica tables across several AWS regions
Aggregate logs, automate log analysis for errors and notify IT operations when errors breached certain threshold - Download and install Amazon CloudWatch Agent in on-premises servers and send logs to Amazon cloudwatch logs


Test # 2
---------

Design for new solutions
Continuous improvement for existing solutions
Design solutions for organizational complexity
Accelrate workload migration and modernization
Migration planning

Confidential files shared via Amazon S3 should only be accessible through CloudFront - Create an Origin Access Identity and associate it with your CloudFront distribution

Design network so that it allows autonomy for the administrators of individual AWS accounts to modify their route tables freely, wants to monitor outbound traffic - Create a shared transit gateway, have each spoke VPC connect to the transit gateway. Use fleet of firewalls, each with a VPN attachment to transit gateway

Consistent high performance network for a web application. Using on-premises data center, company ingests raw feeds from stock market, transforms it, and sends it to internal Apache Kafka cluster for processing. Cluster output to be send to AWS by building a scalable and near real-time solution that will provide stock market data to web application 
- Write a lambda function to process the Amazon Kinesis data stream and create a WebSocket API in Amazon API Gateway to invoke the function. Send the callback messages to connected clients by using the @connections command for the API
- Pull messages from on-premises Apache Kafka cluster by using a fleet of Amazon EC2 instances in Auto Scaling Group. Send the data into an Amazon Kinesis data stream by using Amazon Kinesis Producers library

Replay attack detected on network, originator is trying to intercept data with an intent to re-transmit it - Configure a challenge-handshake authentication protocol (CHAP) to authenticate iSCSI and initiator connections

Secure website with an HTTPS connection. Application architecture uses an Application Load Balancer in front of two on-demand ec2 instances located in two availability zones - Generate a public certificate in ACM. Configure the application load balancer to use the public certificate to handle HTTPS requests

Tech company runs industrial chain orchestration software on the AWS cloud. Web application tier currently deployed on fixed fleet of Amazon RDS. Web and database tiers are deployed in the public and private subnet of the VPC respectively 
- Create a Non-Alias record in route53 with a multi-value answer routing configuration and all the IP addresses of your web application
- Place an application load balancer in front of all the web servers. Create a new Alias record in Route53 which maps to DNS name of load balancer

Multi-tiered web application consists of multiple components, all of components would be using different IP addresses and they are all hosted on one, extra large EC2 instance as main server. 2 separate SSL certificates are to be implemented for 2 separate components - Launch an on-demand EC2 instance that has multiple network interfaces with multiple elastic IP addresses

Migrate legacy Oracle database from on-premises data center to AWS - Migrate the database using the AWS Database migration service and use a cold HDD (sc1) EBS volume

A new feature to be added to an app, which ought to be hosted on a separate set of servers, Use AWS Opsworks as an application lifecycle tool to simplify the management of the app and reduce time-consuming deployment cycles - Create an AWS Opswork stack, with two layers and one custom recipe

All of company's AWS accounts are under OrganizationA, a certain feature of the application must allow AWS resources access from a third-party account which is under AWS organization named Organization B. Company wants to follow security best practises and grant least-privilege access using API or CLI to third-party account - Third party account should create an external ID that will be given to organization A. Logistics company should then create an IAM role with the required access and put the External ID in the IAM role's trust policy. Third party account should use IAM role's ARN and External ID when requesting access to AWS resources

CloudFormation used to deploy an application using s3 and rds. Same application can be deployed once again using CloudFormation. 100 chracter summary in rds to be retained for next compeition - Set the DeletionPolicy on the s3 resource declaration in the CloudFormation template to retain. Set the RDS resource declaration DeletionPolicy to Snapshot.

Provide auditor access to the logs of your AWS resources. S3 for scalable storage, DynamoDB as a NoSQL database, and fleet of EC2 instances to host their web servers - 
1. Enable CloudTrail logging to required AWS resources 2. Create an IAM user with read-only permissions to the required AWS resources 3. Provide the access credential to the auditor

New website for users to view tutorials, contains static media files that are stored on a private Amazon S3 bucket while dynamic contents are stored on AWS Fargate Cluster, Ensure that both static and dynamic content is done through CloudFront only - Use CloudFront to add a custom header to all origin requests. Using AWS WAF, create a web rule that denies all requests without this custom header. Associate the web ACL to the Application Load balancer

Blogging site, blog size is 300 KB, access of blogs drops after 6 months, and after year blogs are rarely accessed, Company wants to use CloudFront to improve the load times of the blogging platform - You can use one s3 source bucket that is partitioned according to the month a blog entry was submitted, and store the entry in that partition. Create a CloudFront distribution with access permission to s3 and is restricted only to it.

Analytics application, 10,000 hours of compute time is required every month, reporting service, needs to run continuously to distribute analytical reports - Deploy the analytics service on a fleet of Amazon EC2 spot instances in the AutoScaling group, Configure a custom metric to scale the spot fleet to meet the needed capacity. Create a container for the reporting service and run it on Amazon ECS with AWS Fargate

IP Cameras take images, which are to be detected for faults by AWS SageMaker, workers should receive notification from on-prem linux servers, Solution to be made available when internet connectivity is down - Deploy the AWS IoT GreenGrass client software to another local server. Run ML inference on the green grass server from the ML model trained from Amazon SageMaker

Instances launched on public subnet should be able to access product updates and patches from internet. company wants to explicitly deny any other outbound connections from VPC instances to hosts on the internet -  You can use a forward web proxy server in your VPC and manage outbound access using URL based rules. Default routes are also removed

Company wants data scientists to be able to launch a jupyter notebook instance, data at rest on storage volume of the notebook instance to be encrypted - Write an AWS Cloud Formation template that contains AWS::SageMaker::NotebookInstance resource type to launch a jupyter notebook instance with preconfigured AWS KMS key, Create mappings on the CloudFormation to map simpler parameter names for instance sizes. Create portfolio in AWS Service Catalog and upload the template to be shared with IAM role of data scientist

Webportal deployed to AWS. Portal must authenticate against their on-premises LDAP server. Each Amazon S3 bucket can only be accessed by a logged-in user, if it belongs to that user 
- Authenticate against LDAP using an identity broker you created, and have it call IAM security token service (STS) to retrieve IAM federated user credentials. IAM federated user credentials are then retrieved from the identity broker to access the appropriate s3 bucket.
- Application first authenticates against LDAP to retreive the name of the IAM role associated with the user. It then assumes that role via a call to IAM security token service (STS). Afterward, the application can now use the temporary credentials from the role to access the appropriate s3 bucket

Online portal of A bank uses SSL for better security, bank wants to implement a separation of responsibilities between the DevOps team and the CyberSecurity team, devops team can login to ec2 instances while cybersecurity team has exclusive access to applications's X.509 certificate - Configure an IAM policy that authorizes access to the certificate store only for the cybersecurity team and then add a configuration to terminate the SSL on ELB

Mitigate distributed denial of service attacks, notification for incoming Layer3 or Layer4 attacks such as SYN flood attacks and UDP reflection attacks, protect against SQL injection, cross-site scripting and other layer 7 attacks 
- Use AWS WAF to define customizable web security rules that control which traffic can access your web applications
- Use AWS Shield Advanced which provides enhanced DDoS attack detection and monitoring for application-layer traffic to your AWS resources

150 VMs using 50 TB of storage on the on-prem data center, migrate whole environment to aws, not during business hours, and just 12 Mbps of bandwidth for migration, Cost effective plan to complete migration - Use AWS application migration service to migrate the mission critical virtual machines to AWS, Request AWS snowball device and transfer exported VMs to it. Once VMs are on Amazon s3, import the VMs to Amazon EC2 instances using VM import/export service

Requirement to store 20 TB worth of scanned files for relief operation, which can grow to total of 50TB of data, Have a website with a search feature that can be used to easily find a certain item through thousands of scanned files 
- Setup a new s3 bucket with standard storage to store and serve scanned files
- Use cloud search for query processing and use Elastic Beanstalk to host the website across multiple availability zones

Meter sends data every 5 minutes to an amazon api gateway which is then processed by several lambda functions, before storing to Amazon DynamoDB table, lambda function takes about 5 to 10 seconds to process data, Running Lambda Functions shows errors such as TooManyRequestsException and ProvisionThroughPutExceededException error when performing PUT operation on the DynamoDB table 
- Process the data in batches to avoid reaching the write limits to the DynamoDB table. Groups the requests from API Gateway by streaming the data into an Amazon Kinesis data stream
- As more customers are sending data, adjust the write capacity unit (WCU) of the DynamoDB table to be able to accomodate all the write requests being processed by the lamdba functions

Adding a cost-effective, location based alert to their ios and android apps, real-estate offers in proximity to their current location, delivery time to be less than a minute - Mobile app would send the user's location to an SQS queue and a fleet of On-Demand ec2 instances would retreive the relevant offers from a dynamodb table, use AWS SNS push to send offers to mobile app

Developers from specific business unit accidentally terminated Amazon EC2 instances, EKS clusters and Aurora Serverless databases owned by other business units - Group accounts to OU, Create IAM role in production account which has a policy that allows access to EC2 instances including resource level permissions to terminate the instances owned by a particular business unit


Multiple persistent storage layers for service object meta data and durable storage for static content, requests to service should be authenticated and securely processed 
- Amazon API Gateway with the required resources and methods
- Unique lambda function to process each resource and configure API Gateway methods with proxy integration to the respective lambda functions
- Control user access to API by using Amazon Cognito User Pools
- Store service object meta -data in Amazon DynamoDB table with auto-scaling enabled
- Secured s3 bucket to store static content
- Generate pre-signed URL when referencing objects stored in s3 bucket

DevOps engineer terminated ec2 instance in production, only solutions architect should be allowed to terminate instance in production 
- Add tags to EC2 instances in the production environment and add resource-level permissions to developers with an explicit deny on terminating the instance which contains the tag
- Modify the associated IAM role assigned to the developers by removing the policy that allows them to terminat EC2 instances in production

Dedicated group of on-premises servers to process the photos and use an open source messaging system to deliver job information to servers. after processing data would go to a tape library and be stored for long-term archival - Create an Auto-Scaling group of spot instance workers that scale according to queue depth in SQS to process job messages. After data is processed, transfer your s3 objects to amazon glacier

Enabling the versioning in the bucket, and after a few days, the new MNL-O.config configuration file for Oceania region has been uploaded

Database is deployed on Multi-Availability zone configuration in Amazon RDS, During the RDS maintenance window, the operating system of the primary db instance undergoes software patching, that triggers the failover process, what would happen to database during failover - The canonical name record (CNAME) is changed from the primary database to the standby database

Reduce the amount of time spend migrating database instances from the on-premises data center by migrating to a managed relational database service in AWS such as Amazon RDS, what is cost effective migration strategy - Replatform

ELB which has a set of EC2 instances behind them, SSL key used to encrypt data is to be secured at all times, application logs should only be decrypted by a handful of key users - Use AWS CloudHSM instance to perform the SSL transactions, persist your application server logs to a private s3 bucket using SSE

Online stock trading application uses RDS to host the database, In event of failure, RTO must be less than 2 hours and RPO must be 10 minutes to meet the compliance requirements 
- Setup AWS Backup plan for the Amazon RDS database with the continous backups for point-in-time recovery (PITR) option enabled
- Take hourly database backups and export to an s3 bucket with transaction logs stored in s3 every 5 minutes. Setup a cross-region replication (CRR) to another AWS region

Online gambling site is hosted in two EC2 instances inside a VPC, in same AZ but in different subnets. First EC2 instance is running a database and the other EC2 instance is a web application that fetches from database, You are required to ensure that two ec2 instances can connect with each other in order for your application to work properly, you also need to track historical changes to security configurations associated to your instances 
- Check and configure the network ACL to allow communication between the two subnets, Ensure that the security group allow the application host to talk to the database on the right port and protocol
- Use AWS config to track historical changes to the security configurations associated to your instances

Service hosted on a fleet of on-demand ec2 instances, load balanced by an application load balancer, On-demand EC2 instances in one of the AZs are not receiving requests - Availability zone not receiving traffic was not associated with the application load balancer

Website remains available in case of database server failures - Create an Oracle database in RDS with Multi-AZ deployments

Loading time of game assets and data are quite sluggish including their static content - Use cloudfront to distribute their static content and elasti-cache as an in-memory data store

Visitors will first login to the site using social media credentials and add items to cart, Company needs to build a checkout system that can handle sudden surge of incoming traffic 
- Combine an Elastic load balancer in front of an auto-scaling group of web servers with CloudFront for fast delivery
- Web servers will first authenticate the users by logging into their social media accounts which are integrated in Amazon Cognito, then process the user's purchases and store them into an SQS queue using IAM roles for EC2 instances to gain permissions to the queue
- Finally, items from the queue are retrieved by a set of application servers and stored in a dynamo db table

Call center company is using custom application to process and store call recordings in its on-premise data center, recordings stored on NFS share, an offshore team is contracted to transcribe about 2% of the call recordings to be used for quality assurance purposes. Web portal is available for the quality assurance team to review the call recordings, after 90 days the recording are sent to an offsite location for long-term storage
- Store all recordings in an Amazon s3 bucket
- Create an s3 life-cycle policy to move objects older than 90 days to Amazon S3 glacier
- Create an AWS Lambda trigger to start a transcription job using Amazon transcribe
- Update the web portal, so that it can be hosted on an Amazon S3 bucket, Amazon API Gateway and AWS Lambda

Newspaper website, articles have a cover image and 200 words, news articles high browsed for first 2 months, rarely accessed after an year, readers are leaving alot of  comments in first 3 months of publishing 
- Use Amazon RDS multi-AZ deployments with Read Replicas. Use s3 to store the static data such as the cover images and other media
- Use CloudFront as Content Delivery network to load articles much faster anywhere in globe

There is total of 1,000 TB of data files that need to be mounted to a single folder on the file server. Existing users must also be able to access portions of this data while backups are taking place 
- Provision Gateway Cached Volumes from AWS Storage Gateway

E-Commerce company is running a three-tier application on AWS, RTO of 5 minutes and RPO of 1 hour on the backup site in the event application goes down, a requirement for the backup site to be atleast 250 miles away from the primary site 
- On the backup region, create a scaled down version of the fully functional environment with one EC2 instance of web server and applicaiton server in their own auto-scaling groups behind application load balancers
- Create a standby database instance, that replicates data from the primary database
- In case of disaster, scale the instances to meet the demand and update the Amazon Route53 record to point to the backup region

Have the ability to deploy exact copies of different versions of cloud infrastructure, stage changes into different environments, revert back to different versions and identify specific version running in the VPC, all new public facing applications should have a global content delivery network - use AWS Cloud formation to manage the cloud architecture and CloudFront as CDN

Secure credentials that are used to access the database tier, use CloudFormation to deploy a three-tier web application that consists of a web tier, an application tier and a database tier that will utilize Amazon DynamoDB for storage - Create an IAM role and assign the required permissions to read and write from dynamodb table. Have the instance profile property of the application instance reference the role

Application interacts with million of requests per day to fetch various medical data of their patients, system is composed of a web tier, an application tier and a database tier that receives large and unpredictable traffic demands, infrastructure is highly available and scalable enough to handle web traffic fluctuations demand
- Run the web and application tiers, in stateless instances, in an auto-scaling group
- Use ElastiCache memcached for tier synchronization and
- CloudWatch for monitoring
- Run database tier, using RDS with read replicas

With sudden increase in user traffic, the fleet of Amazon EC2 instances experienced high CPU usage and users are reporting sluggishness on the website
- Create an Amazon S3 bucket to host the static contents
- Set this bucket as the origin for an Amazon CloudFront distribution
- Write a Lambda@Edge function to parse the User-Agent HTTP header and serve the appropriate contents based on the user device type

Solutions architect has been tasked to allow on-premises users, who are already signed in using their corporate accounts, to manage AWS resources without creating separate IAM users for each of them, this is to avoid having two separate login accounts and memorizing multiple credentials
- Authenticate using your on-premise SAML 2.0-compliant identity provider (IDP)
- Retrieve temporary credentials using STS
- And grant federated access to the AWS Console via the AWS Single Sign ON endpoint using a browser

A new VPC in us-west-1 region, where they will launch the Amazon EC2 instances that will host the web application, company wants to have a disaster recovery website in the us-east-1 region that will act as a passive backup of the running application
- Create an application load balancer (ALB) in the us-west-1 region that spans multiple availability zones of the VPC
- Create an auto scaling group that will deploy ec2 instances across the multiple AZs and place it behind the ALB
- Setup the same configuration to the us-east-1 region VPC
- Create record entries in Amazon Route53 pointing to the ALBs with health check enabled and a failover routing policy

RDS instance is always effected and always goes down when there is a problem in an Availability zone, solutions architect was tasked to analyze the current architecture and to solve user complaints about website, solutions architect should implement a system that automatically discovers, classifies, and protects personally identifiable information (PII) data in Amazon S3 bucket
- Use Amazon Macie to automatically discover, classify and protect personally identifiable information (PII) data in the Amazon s3 bucket
- Use a life-cycle policy in s3 to move the old photos to infrequent access storage class after a month
- Re-configure the existing database to use RDS Multi-Az deployments

To make sure that each account is kept within budget, the administrators in the master account must have the power to stop, delete or terminate resources in both development and test environment AWS accounts - 
- First create IAM users in the master account
- Then in the Dev and Test accounts, generate cross-account roles that have full admin permissions while granting access for the master account


Automate the patch management process of the operating system in which the database runs, as well to setup scheduled backups to comply with the company's disaster recovery plan
- Migrate the database to a cluster of EBS-backed Amazon EC2 instances across multiple AZs
- Automate the creation of EBS snapshots from EBS volumes of the EC2 instance by using Amazon Data Lifecycle manager
- Install the SSM agent to the EC2 instance and automate patch management process using AWS Systems Manager patch manager

A lambda function used for copying objects to s3 bucket may affect other critical lambda functions because of the regional concurrency limit in AWS Lambda
- Configure a reserved concurrency limit for the new function to ensure that its execution will not exceed this limit
- Use Amazon CloudWatch alarms to monitor the throttle metrics for lambda functions to ensure that the concurrency limit is not being reached

Data protection at rest, stored data on disks in Amazon s3 data centers. Data protection in transit, means that data should be secured while it travels to and from s3
- SSE-S3 provides strong multi-factor encryption in which each object is encrypted with a unique key
- It also encrypts the key itself with a master key that it rotates regularly

Improve the performance of the cloud front distribution by increasing the proportion of your viewer requests that are served from CloudFront edge caches instead of going to your origin servers 
- Configure the CloudFront origin to add a Cache-Control max-age directive to your objects and specify the longest practical value for max-age
- Use an SSL/TLS certificate provided by AWS Certificate Manager (ACM)

Synchronize the patch base-lines being used on-premises to all of the EC2 instances, in your VPC, as well as to automate patching schedule
- Use AWS Systems Manager Patch Manager to manage and deploy the security patches of your EC2 instances based on the patch baselines from your on-premises data center
- Install the SSM agent to all of your instances and automate patching schedule by using AWS Systems Manager Maintenance Windows

Thousand of virtualized Linux and Windows servers on its on-premises data centers, range of Java and PHP applications that are using MySQL and Oracle Databases, Analyze the current environment and estimate the cost of migrating resources to the cloud
- Use AWS Migration Hub to discover and track the status of the application migration across AWS and partner solutions
- Use the AWS Cloud Adoption Readiness tool (CART) to generate a migration assessment report to identify gaps in organizational skills and processes
- Use the AWS Application Discovery Service to gather information about the running virtual machines and running applications inside servers

Application is hosted on a fixed set of Amazon EC-2 instances in the us-east-1 region, using mobile phones, the artists can scan and upload large, high resolution images of their art work which are stored in a centralized amazon s3 bucket in the same region, slow performance on their image uploads - Enable Amazon S3 transfer acceleration on the central s3 bucket. Use the s3-accelerate endpoint to upload the images

E-Commerce platform launched on a fleet of on-demand EC2 instances that are launched in public subnet, Instances only initiate outbound requests to specific URLs provided by the proprietary e-commerce platform while accepting all inbound requests from the online shoppers - In your VPC, launch a new web proxy server that only allows outbound access to URLs provided by the proprietary e-commerce platform

Several VPCs in the AWS Cloud, where it uses NAT instanes to allow multiple EC2 instances from the private subnet, Numerous incidents where NAT instance is not available, which affects the batch processing of different applications
- Create a NAT gateway then specify its corresponding subnet and elastic IP address
- Update the routetable of the private subnet to point the internet traffic to the NAT gateway

Solution Architect launched several EC2 instances in VPC, however, the instances were not able to resolve the companys custom AD domain name 
- Create a forwarding rule inside the endpoint to forward any queries for private.tutorialsdojo.com to the IP address of the two domain controllers
- Create an outbound endpoint on the Amazon Route53 console, set the AmazonProvidedDNS as the DNS resolver for the VPC

Application receives an order and it sends and email to the employees with the information needed for the package shipment, after shipment, employee replies to email, Company wants to migrate to a serverless application model to stop relying on emails and minimize operational overhead for the application
- Store order information in Amazon DynamoDB table
- Create AWS step function workflow that will be triggered for every new order
- Once the package is scanned and leaves warehouse, trigger an AWS Lambda to mark the order as completed, and complete the AWS Step Function workflow

Enterprise proprietary issue tracking system, application would have steady-stage usage and the database would be used for online transaction-processing (OLTP) 
- Use CloudFormation template to launch an Auto-Scaling group of EC2 instances across multiple availability zones, which are all connected via an ELB to handle load balancing
- Leverage on CloudFront in distributing your static content and a RDS instance with Multi-AZ deployment configuations

50 TB of log files on-premises, solutions Architect requested an AWS snowball edge device that would be used to transfer the files to Amazon S3, file interfaces was configured on the snowball edge device and is connected to corporate network, copying of data is slow with snowball cp command 
- Encryption overhead, when copying files to snowball edge device
- Open multiple sessions to snowball edge device and initiate parallel copy jobs to improve the overall copy throughput

Solutions Architect is using AWS CloudFormation templates for infrastructure as code of its two-tier web application, database password must be rotated every 60 days
- Create an AWS Secrets Manager secret resource for the database password
- Modify the application to retrieve database password from Secrets Manager when it launches
- Use a dynamic reference for the secret resource to be placed as the value of the MasterUserPassword property of the AWS::RDS::DBInstance resource

Photo-Sharing app will store pictures direclty uploaded by users in a single s3 bucket and users will be able to view and download their own pictures directly from s3 bucket, Solutions Architect must ensure the security of the application, and it should be able to handle potentially million of users in the most secure manner
- Store user information in Amazon RDS and create an IAM role with appropriate permissions
- Generate new temporary credentials using the AWS Security Token Service 'AssumeRole' function every time the user uses their mobile app and creates new temporary credentials
- Credentials will be stored in the mobile app's memory and will be used to access Amazon S3

Central logging service running on an Auto-Scaling group of Amazon EC2 instances, logging service receives logs from AWS accounts through connectivity provided by AWS privateLink, interface endpoint for this is available on each of the client AWS accounts, Clients unable to submit logs through the VPC endpoint
- Ensure that security group attached to EC2 instance hosting the logging service, allows inbound traffic from the NLB subnet IPs
- Ensure that NACL associated with the logging service subnet allows communication to and from the EC2 instances subnets running the logging service

Mobile app would send photos to a web server hosted on EC2, which adds a photo mark to each photo, Design a solution where the photos generated by the server will be uploaded to an s3 bucket for durable storage
- Setup an IAM role with permission to list and write objects to the s3 bucket
- Attach the IAM role to the EC2 instance which will enable it to retreive temporary security credentials from the instance meta-data and use that access to upload the photos to s3 bucket

Analyze each web visitor's click stream data on the website to populate user analytics, which gives them insight about the sequence of pages and advertisements the visitors have clicked, data will be processed in realtime to transformt the page layout as the visitors click through the web portal to increase revenue of company - 
Push web clicks by session to Amazon Kinesis and analyze behaivor using Amazon Kinesis workers

Implement a single-signon feature to allow the employees to use their existing windows account password to connect and use various AWS resources
- Use AWS directory service to integrate your AWS resources with existing Active Directory using trust relationships
- Enable single-sign-on using Managed Microsoft AD

Multi-layered, java based content management system hosted on on-premises data center, CMS has JBoss application server present in application tier, database consists of Oracle database which is regularly backed up to s3 using Oracle RMAN backup utility, applictions static files and content are kept on 512 GB storage gateway volume, Solutions Architect was tasked to create a disaster recovery solution for the application and its data
- Provision EC2 servers for both your JBoss application and Oracle database, restore the database backups from an s3 bucket
- Provision an EBS volume containing static content obtained from storage gateway, and then attach the volume to the JBoss Ec2 server

Company has financial files stored in s3 bucket, which is behind CloudFront, at present clients can access their data by directly using an s3 url or using their cloud front distribution, Company wants to deliver their content to a specific client in california and need to make sure that only that client can access the data
- Create a new s3 bucket in US West region and upload the files
- Use s3 pre-signed URLs to ensure that only their client can access the files
- Remove permission to use Amazon S3 URLs to read the files for anyone else

- Use CloudFront signed URLs to ensure that only their client can access the files
- Create an origin-access identity (OAI) and give it permission to read the files in the bucket
- Remove permission to use Amazon S3 URLs to read the files for anyoone else

Solution Architect has been successfully granted access to AWS environment through the federated identity web portal
Other test users who tried to authenticate through the federated identity web portal are not given access to the AWS environment
- Ensure that appropriate IAM roles are mapped to company users and groups in the Idp's SAML assertions
- Ensure that the trust policy of the IAM roles created for the federated users or groups has set the SAML provider as the principal
- Ensure that ARN of SAML provider, the ARN of the created IAM role, and SAML assertion from the Idp are all included when the federated identity portal calls the AWS STS AssumeRoleWithSAML API


Test # 5 
----------

============

A team collects and routes behavioral data for an entire company
Company runs a Multi-AZ VPC environment with public subnets, private subnets and internet gateway
Each public subnet also contains a NatGateway
Cost in EC2-Other category is consistently higher. NatGateway bytes charges are increasing cost in Ec2 other category

------

Add an interface VPC endpoint for Kinesis Data Streams to the VPC
Ensure that the VPC endpoint policy allows traffic from the applications

==========

Public Amazon API Gateway endpoint invokes the lambda function
Lambda function and API Gateway endpoint reside in the us-east-1 region
Redesign the application to support failover to another AWS Region

-----

Create an Amazon Simple Queue Service (SQS) queue
Configure API Gateway to direct traffic to the SQS queue instead of to the Lambda function
Configure the lambda function to pull messages from the queue for processing

=======

User uploaded videos are stored on Amazon EBS volumes and analyzed by custom recognition software for categorization

Website contains static content that has variable traffic which peaks in months

Architecture consists of Amazon EC2 instances running in AutoScaling group for web applications and EC2 instances running in an AutoScaling group to process an Amazon SQS queue

Re-architect the application to reduce operational over-head using AWS managed services, where possible, and reduce opertional overhead using AWS managed services 

-----

Use AWS Elastic Beanstalk to launch Ec2 instances in an Auto-Scaling group for the web application and launch a worker environment to process the SQS queue

Replace the custom software with Amazon Rekognition to categorize the videos

========

Application runs on several Amazon EC2 Linux instances in an auto-scaling group in a private subnet

AWS Systems Manager Session Manager is configured, and AWS Systems Manager Agent is running on all EC2 instances

Company recently released a new version of the application

Some EC2 instances are being marked as unhealhty and are being terminated

As a result application is running on reduced capacity

--------

Suspend the Auto Scaling group's terminate process. Use session manager to log in to an instance that is marked as unhealthy

======

Delivery management system on AWS

Drivers report delivery, drivers hand held device, uploads signatures and photos through FTP to a single Amazon EC2 instance

Each hand-held device saves a file in a directory based on signed-in user, and file name matches the delivery number. EC2 instance adds meta-data to the file, and file is placed on s3 for archiving.

As system expands, drivers are reporting that system is rejecting connections

FTP server is having issues due to lack of memory, and dropping connections

------

Use AWS Transfer Family to create an FTP Server, that places the files in Amazon Elastic File System (Amazon EFS)

Mount the EFS volume to the existing EC2 instance

Point the EC2 instance to new path for file processing

========

Company is using AWS Control Tower to deploy a landing zone for the organization

Company wants to implement governance and policy enforcement

Company must implement a policy that will detect Amazon RDS DB instances that are not encrypted at rest in the company's production ou

------

Enable the appropriate gaurd-rail from the list of strongly recommended guard-rails in AWS Control Tower

Apply the gaurd-rail to the production OU

========

Application consists of dynamic content that is created on a set of Amazon EC2 instances

EC2 instances run in an Auto-Scaling group that is configured as a target group for an application load balancer

Company is using Amazon CloudFront distribution to distribute the application globally

CloudFront application uses ALB as origin

Company uses Amazon Route53 for DNS and has created an A record of www.example.com for CloudFront distribution

Solution Architect must configure the application so that its highly available and fault tolerant

-----

Provision an ALB, an Auto-Scaling group, and EC2 instances in a different AWS Region

Update the CloudFront distribution, and create a second origin for the new application load balancer

Create an origin group for the two origins

Configure one origin as primary and one origin as secondary

=========

Application runs on a group of Amazon EC2 instances in an application VPC located in the us-east-1 region with an IPv4 CIDR block of 10.10.0.0/16 

In a different AWS account, a shared services VPC is located in us-east-2 region with an IPv4 CIDR block of 10.10.10.0/24

When a Cloud Engineer uses AWS Cloud Formation to attempt to peer the application VPC with the shared services VPC, an error message indicates a peering failure

-----

The IPv4 CIDR ranges of the two VPCs overlap

The IAM role in the peer acceptor account doesn't have the correct permissions

========

Company wants to migrate its workloads from on-premises to AWS
Workloads run on Linux and windows
Large on-premises infrastruture that consists of physical machines and VMs that host numerous applications

- Must capture detail about the system configuration, system performance, running processes, and network connections of its on-premises network
- Divide the on-premises applications into groups for AWS migrations
- Recommendations for Amazon EC2 instance types so that company can run its workloads on AWS in most cost-effective manner

-----

Assess the existing applications by installing AWS Systems Manager agent on the Physical Machines and VMs

Group servers into applications for migration by using AWS Migration Hub

Generate recommended instance types and associated costs by using AWS Migration Hub


=========


Structured AWS accounts to be part of an Organization in AWS Organization

Company has setup consolidated billing, and has mapped departments to following OUs
- Finance
- Sales
- HR
- Marketing
- Operations

Each OU has multiple AWS accounts, one for each environment within a department, environments are test, pre-production, production

HR is releasing a system that will launch in 3 months

HR has purchased several reserved instances in production AWS account, and wants to make sure that other departments could not share the RI discounts

------

In the AWS Billing and Cost Management console, use the organizations management account ti turn off RI sharing for the HR departments' production AWS account

========

Company is developing and hosting several projects in the AWS Cloud

Company requires the cost of cloud infrastructure to be allocated to owning project

Team responsible for all of the AWS accounts has discovered, that several Amazon EC2 instances are lacking the project tag used for cost allocation

-----

Use Amazon Inspector in the organization to find resources with missing tags

Create an IAM policy in each account with a deny action for ec2:RunInstance if the project tag is missing

Create an AWS Config aggregator for the organization to collect a list of EC2 instances with the missing project tag

========

Company used Amazon EC2 instances to deploy a web fleet to host a blog site

Ec2 instances are behind an application load balancer and are configured in an Auto Scaling group

Company added a feature for bloggers to add videos for their posts, attracting 10 times the previous user traffic

At peak times of day, users report buffering and timeout issues while attempting to reach the site or watch videos

------

Configure an Amazon CloudFront distribution

Point the distribution to an S3 bucket, and migrate videos from EFS to Amazon S3

========

On-premises monitoring solution using a PostgresSQL database for persistence of events
Database is unable to scale and frequently runs out of storage

Company has setup a VPN connection between its network and AWS

Solution should include the following attributes

- Managed AWS services to minimize operational complexity
- A buffer that automatically scales to match throughput of data and requires no ongoing administration
- A visualization tool to create dashboards to observe events in real time
- Support for semi-structured JSON data and dynamic schemas

----

Use Amazon Kinesis Data Firehose to buffer events, Create an AWS Lambda function to process and transform events

Configure Amazon Elasticsearch service (Amazon ES) to receive events. Use the Kibana endpoint deployed with Amazon ES to create near real-time visualizations and dashboards

=========

Electronic document management system, in which users upload their documents

Application stack is entirely serverless and runs on AWS in the eu-central-1 region

System includes a web application that uses an Amazon CloudFront distribution for delivery with Amazon S3 as the origin

Web application communicates with Amazon API Regional Gateway endpoints

API Gateway APIs call AWS Lambda functions that store metadata in an Amazon Aurora Serverless database and put the documents in an S3 bucket

Company must improve latency outside of Eurpoe

------

Enable s3 transfer accelration on the s3 bucket. Ensure that the web application uses the transfer accelration signed URLs

Change the API Gateway Regional Endpoint to edge-optimized endpoints

=========

Solution architect used an AWS Cloud Formation template to create the SNS topic and stack sets to automate the deployment of Cloud Formation stacks

Solution architect do to deploy CloudFormation StackSets in all AWS accounts

----

Create a stack set in the Organizations management account

Use service managed permissions

Set deployment options to deploy to the organization

Enable CloudFormation StackSets automatic deployment

=======

On-premise website application that provides real-estate information for potential renters and buyers

Website uses a Java backend and a NoSQL MongoDb database to store subscriber data

Company needs to migrate entire application to AWS with a similar structure

Application must be deployed for high availability, and company cannot make changes to application

------

Configure Amazon DocumentDB (with MongoDB compatibility) in on-demand capacity mode in multiple availability zones as database for subscriber data

Deploy Amazon Ec2 instances in an Auto-Scaling group, across multiple availability zones for the Java Back End Application

===========

Weather service provides high-resolution weather maps from a web application hosted on AWS in eu-west-1 region

Weather maps are updated frequently and stored in Amazon s3 along with static HTML content

Web application is fronted by Amazon CloudFront

Company recently expanded to serve users in us-east-1 region, and new users report that viewing respective weather maps is slow from time to time

------

Create a new s3 bucket in us-east-1. Configure S3 cross-region replication to synchronize from the s3 bucket in eu-west-1

Use Lambda@Edge to modify requests from  North America to use the S3 bucket in us-east-1

=======

Company running application on AWS in multi-account environment

Company's sales and marketing team use separate AWS accounts in AWS organizations

Sales team stores peta bytes of data in Amazon S3 bucket

Marketing team uses Amazon Quick Sight for data visualization

Marketing team needs access to data that the sales team stores in s3 bucket

Company has encrypted the s3 bucket with an AWS Key Management Service (AWS KMS) key

Marketing team has already created the IAM service role for QuickSight to provide QuickSight access in the marketing AWS account

A solution that will provide secure access to the data in the s3 bucket across AWS accounts

------

Create an IAM role in the sales account and grant access to the s3 bucket

From the marketing account, assume the IAM role in the sales account to access the s3 bucket

Update the Quicksight rote, to create a trust relationship with the new IAM role in the Sales account

========

Sequencing data is generated and stored on local storage area network (SAN), and then data is processed

Research and development teams are running into capacity issues and have decided to re-architect their genomics analysis platform on AWS to scale based on workload demands and reduce the turn-around time from weeks to days

Company has a high-speed AWS Direct Connect connection

Sequencers will generate around 200 GB of data for each Genome, and individual jobs can take several hours to process the data with ideal compute capacity

End result would be stored in Amazon S3

Company is expecting 10-15 job requests each day

------

Use AWS DataSync to transfer the sequencing data to Amazon S3

Use s3 events to trigger an AWS Lambda function that starts an AWS Step Functions workflow

Store the Docker images in Amazon Elastic Container Registery (Amazon ECR) and trigger AWS Batch to run the container and process the sequencing data

==========

Company uses a service to collect meta-data from applications that the company hosts on-premises

Consumer devices such as TVs and internet radios access the applications

Many older devices donot support certain HTTP headers and exhibit errors when these headers are present in responses

Company has configured an on-premises load-balancer to remove the un-supported headers from responses send to older devices, which the company identified by User-Agent headers

Company wants to migrate the service to AWS, adopt serverless technologies, and retain the ability to support older devices

------

Create an Amazon API Gateway REST API for the meta data service

Configure API Gateway to invoke the correct Lambda function for each type of request

Modify the default gateway responses to remove the problematic headers based on the value of User-Agent header

======

Company wants to deploy AWS WAF solution to manage AWS WAF rules across multiple AWS accounts

Accounts are managed under different OUs in AWS Organizations

Administrators must be able to add or remove accounts or OUs from managed AWS WAF rule sets as needed

Administrator must also have the ability to automatically update and remediate non-compliant AWS WAF rules in all accounts

-----

Use AWS Control Tower to manage AWS WAF rules across accounts in organizations

Use AWS Key Management Service (AWS KMS) to store account numbers and OUs to manage

Update AWS KMS as needed to add or remove accounts or OUs

Create IAM users in member accounts

Allow AWS Control Tower in the management account to use the access key and secret access key to create and update AWS WAF rules in member accounts

========

Store large number of archived documents and make documents available to employees through the coporate intranet

Employees will access the system by connecting through a client VPN service that is attached to a VPC

Data must not be accessible to public

Documents that company is storing are copies of data that is held on physical media elsewhere

Number of requests would be low

Availability and speed are not concerns of company

------

Create an Amazon S3 bucket

Configure the S3 bucket to use the S3 Glacier Deep Dive Archive storage class as default

Configure the S3 bucket for website hosting

Create an S3 interface endpoint

Configure the S3 bucket to allow access only through that endpoint

=========

Company is running a two-tier web-based application in an on-premises data center

Application layer consists of a single server running a stateful application

Application connects to a PostGresSQL database running on a separate server

Applications' user base is expected to grow significantly

Company is migrating the application and database to AWS

Solution would use Amazon Aurora PostgreSQL, Amazon EC2 Auto-Scaling, and Elastic Load Balancing

Solution that will provide a consistent user experience that will allow the application and database tier to scale

--------

Enable Aurora AutoScaling for Aurora Replicas, Use an Application Load Balancer with the round-robin routing


========

SaaS based company provides a case management solution to customers as part of the solution

Company uses a stand-alone SMTP server to send email messages from an application

Application also stores an email template for acknowledgement email messages that populate customer data before the application sends the email messages to the customer

Company plans to migrate this messaging functionality to AWS Cloud and needs to minimize operational over-head

Cost effective solution

------

Setup Amazon Simple Email Service (Amazon SES) to send email messages

Store the email template in an Amazon S3 bucket

Create an AWS Lambda function to retreive the template from the s3 bucket and to merge the customer data from the application with the template

Use an SDK in the Lambda function to send the email message

======

Company developed a pilot application by using AWS Elastic Beanstalk and Java

To save costs during development, the company's development team deployed the application into a single-instance environment

Recent tests indicate that the application consumes more CPU than expected

CPU utilization is regularly greater than 85 %, which causes some performance bottle-neck

Solution Architect must mitigate the performance issues before the company launches the application to production

Which solutions will meet these requirements with least over-head

-----

Create a new Elastic Beanstalk application

Select a load balanced environment type

Select all availability zones

Add a scale-out rule, that will run if the maximum CPU utilization is over 85% for 5 minutes

==========

Company runs a python script on an Amazon EC2 instance to process data

Script runs every 10 minutes

Script ingests files from an Amazon S3 bucket and processes the files

On average, script takes approximately 5 minutes to process each file

Script will not re-process a file, that script has already processed

Company reviewed the CloudWatch metrics and noticed that EC2 instance is idle for approximately 40% of the time because of the file processing speed

Company wants to make the workload highly available and scalable, and reduce long term management overhead

--------

Migrate the data processing script to a container image that runs on Amazon Elastic Container Service (ECS) on AWS Fargate

Create an AWS Lambda function that calls the fargate RunTaskAPI operation when the container processes the file

Use an S3 event notification to invoke the lambda function

===========

Company runs its application in the eu-west-1 Region and has one account for each of its environment
	- Development
	- Testing
	- Production

All the environments are running 24 hours a day, 7 days a week by using stateful Amazon EC2 instances and Amazon RDS for MySQL databases

Databases are between 500 GB and 800 GB in sizes

Development and test team work on business days during business hours, but the production enviornment operates 24 hours, 7 days a week

Company wants to reduce costs

All resources are tagged with an environment tag with either development, testing or production as key

How to reduce costs with least operational efforts ?

--------

Create an Amazon event bridge rule that runs once every day

Configure the rule to invoke one AWS Lambda function that starts or stops instances based on tag, day and time

===========

Analyze a company's Amazon EC2 instances and Amazon EBS volumes to determine whether the company is using resources effectively

Company is running several large, high-volume EC2 instances to host database clusters that are deployed in active/passive configuration

Utilization of these EC2 instances varies by the applications that use the databases, and the company has not identified a pattern

Solutions architect must analyze the enviornment and take action based on finding

----

Install the Amazon CloudWatch agent on each of the EC2 instances

Turn on AWS Compute Optimizer, and let it run for atleast 12 hours

Review the recommendations from compute optimizer, and right-size the Ec2 instances as directed

=========

Company is migrating some of its applications to AWS

Company wants to migrate and modernize applications quickly after it finalizes networking and security strategies

Company has setup an AWS Direct Connect Connection in a central network account

Company expects to have hundreds of AWS accounts and VPCs in the near future

Coporate network must be able to access the resources on AWS seamlessly and also must be able to communicate with all the VPCs

------

Create a direct connect gateway and a transit gateway in the central network account. Attach the transit gateway to the Direct Connect Gateway by using a transit

Share transit gateway with other accounts. Attach VPCs to the transit Gateway

Provision only private subnets. Open the necessary route on the transit gateway and customer gateway to allow outbound internet traffic from AWS to flow through NAT services that run in the data center

========

Company is hosting critical application on a single Amazon EC2 instance

Application uses an Amazon ElastiCache for Redis single-node cluster for an in-memory data store

Application uses an Amazon RDS for MariaDB db instance for a relational database

For the application to function, each piece of the infrastructure must be healthy and must be in active state

Improve the application's architecture so that the infrastructure can automatically recover from failure with the least possible downtime

-----

Use an Elastic Load Balancer to distribute traffic across multiple Ec2 instances

Ensure that EC2 instances are part of an Auto-Scaling group that has a minimum capacity of two instances

-------

Modify the DB instance to create a Multi-AZ deployment that extends across two availability zones

-------

Create a replication group for the ElastiCache for Redis Cluster. Enable Multi-Az on the cluster


=============

Digital Marketing company has multiple AWS accounts that belong to various teams

Creative team uses an Amazon S3 bucket in its AWS account to securely store images and media files that are used as the conent for the company's marketing campaigns

Creative team wants to share the s3 bucket with the strategy team so that strategy team can view objects

Solutions Architect has created an IAM role that is named strategy_reviewer in the Strategy account

Solutions archicet has also setup a custom AWS Key Management Service (AWS KMS) key in the creative account and has associated the key with the s3 bucket

-------

Update the strategy_reviwer IAM role to grant full permissions for the S3 bucket and to grant decrypt permissions for the custom KMS key

Update the custom KMS key policy in the Creative account to grant decrypt permissions to the strategy_reviwer IAM role

Update the strategy_reviewer IAM role to grant read permissions for the S3 bucket and to grant decrypt permissions for the custom KMS key

========

Company wants to migrate an application to Amazon EC2 from VM Ware infrastructure that runs in an on-premises data center

A solutions architect must preserve the software and configuration settings during the migration

What should solutions architect do to meet these requirements

------

Create a managed-instance activation for a hybrid environment in AWS system manager

Download and install System Manager agent on the on-premises VM

Register the VM with Systems Manager to be a managed instance

Use AWS Backup to create a snapshot of the VM and create an AMI

Launch an EC2 instance that is based on the AMI

=========

Company uses AWS Organizations for multi-account setup in the AWS Cloud

Company uses AWS Control Tower for governance and uses AWS Transit Gateway for VPC connectivity across accounts

In an AWS application account, the company's application team has deployed a web application that uses AWS Lambda and Amazon RDS

Company's database administrators have a separate DBA account, and use the account to centrally manage all the databases across the organization

Database administrators use an Amazon EC2 instance that is deployed in the DBA account and use the account to centrally manage all the databases across the organization

Application team has stored the database credentials as secrets in the AWS secrets manager in the application account

Application team is manually sharing the secrets with the database administrators

Secrets are encrypted by the default AWS managed key for Secrets Manager in the application account

A solutions architect needs to implement a solution that gives the database administrators access to the database and eliminate the need to manually share the secrets


-------

Use AWS Resource Access Manager (RAM) to share the secrets from the application account with the DBA account

In the DBA account, create an IAM role that is named DBA-admin

Grant the role the required permissions to access the shared secrets

Attach the DBA-admin role to the EC2 instance for access to the cross-account secrets

===========

Data lake hosted on S3

Financial records received over SFTP each night

Company runs its own SFTP server on an Amazon EC2 instance in a public subnet of a VPC

SFTP server is reachable on DNS sftp.example.com through the use of Route53

Improve the reliability of SFTP solution

----

Migrate the SFTP server to AWS Transfer for SFTP. Update the DNS record sftp.example.com in Route53 to point to the server endpoint host name

==========

Serverless application comprised of Amazon CloudFront, Amazon API Gateway and AWS Lambda Function

Current deployment process of the application code is to create a new version number of Lambda function and run AWS CLI script to update

If new fucntion has errors another CLI script reverts by deploying the previous working version of the function

Company would want to decrease the time to deploy new versions of the application and reduce time to detect and revert when errors are identified

-------

Use AWS SAM and built-in AWS CodeDeploy to deploy the new Lambda version, gradually shift traffic to the new version, and use pre-traffic and post-traffic functions to verify code rollback if Amazon CloudWatch alarms are triggered

============

On-Premise data analytics platform

System is highly available in a fully redundant configuration across 12 servers in the company's data center

System runs scheduled jobs, both hourly and daily, in addition to one time requests from users

Scheduled jobs take between 20 minutes to 2 hours to finish and have tight SLA

User jobs finish in less than 5 minutes and have no SLA

During system failures, scheduled jobs must continue to meet SLA, however, user jobs could be delayed


Move the system to Amazon EC2 instances and adopt a consumption based model to reduce costs with no long term commitments

Solution ought to be highly available and must not effect SLAs

-----

Split the 12 instances across three availability zones in the chosen AWS region

Run two instances in each availability zone as on-demand instances with a savings plan

Run two instances in each availability zone  as spot instances

==========

Solution Architect needs to copy data from an S3 bucket in an AWS account to a new S3 bucket in a new AWS account

Solutions Architect must implement a solution that uses the AWS CLI

Which combination of steps will successfully copy the data

-------

Create a bucket policy  to allow the source bucket to list its contents and to put objects and set object ACLs in the destination bucket

Attach the bucket policy to the destination bucket
-------
Create an IAM policy in the destination account. 

Configure the policy to allow a user in the destination account to list contents and get objects in the source bucket, and to list contents, put objects, and set objectACLs in the destination bucket

Attach the policy to the user
-----

Run the aws s3 sync command as a user in the destination account

Specify the source and destination buckets to copy data

=========

Calls to third party servics are causing delays

Currently appliation calls third party services asynchronously by directly invoking an AWS Lambda function

Solution architect need to decouple the third-party service calls and ensure that all calls are eventually completed

------

Use an Amazon Simple Queue Service (SQS) queue to store events and invoke the lambda function

=======

Enterprise allows developers to purcahse third-party software through aWS marketplace

Company uses an AWS Organization account struture with full features enabeld and has shared services account in each OU that will be used by procurement managers

Procurement team wants administration of Private Marketplace to be restricted to a role named procurement-management-role, which could be assumed by procurement managers

Other IAM users groups, roles and account administrators in company should be denied Private Marketplace administrative access

-------

Create an IAM role named procurement manager-role in all AWS accounts that will be used by developers

Add the AWSPrivateMarketPlaceAdminFullAccess managed policy to the role

Create an SCP in organization to deny permissions to administer Private Market place to everyone except the role named procurement-manager-role

Apply the SCP to all the shared servics account in the organization

=======

Copmany is running a traditional web application on an Amazon EC2 instance

Company needs to refactor the application as micro-services that run on containers

Separate versions of the application exist in two distinct environments: production and testing

Load for the application is variable, but the minimum load and the maximum load are known

A solutions architect needs to design the updated application with a server-less architecture that minimizes operational complexity

------

Upload the container images to Amazon Elastic Container registry (ECR)

Configure two auto-scaled Amazon Elastic Container service clusters with the fargate launch type to handle the expected load

Deploy tasks from the ECR images

Configure two separate Application Load Balancers to direct traffic to ECS clusters

===============

Company has organization in AWS organization that has large number of AWS accounts

One of AWS account is desginated as transit account and has a transit gateway that is shared with all of the other AWS accounts

Company's networking team needs to centrally manage a list of internal IP address ranges that belong to global office and the transit account

Company has AWS config enabled on all of its accounts

Company's networking team needs to centrally manage a list of internal IP address ranges that belong to the global office

Developers will reference this list to gain access to their applications securely

-------

In the transit account, create a VPC prefix list with all of the internal IP address ranges

Use AWS resource access manager to share the prefix list with all of tthe other accounts

Use the shared prefix list to configure securty group rules in the other accounts

==========

Company has many AWS accounts and uses AWS organizations to manage all of them

A solutions architect must implement a solution that the company can use to share a common network across multiple accounts

Company's infrastructure team has a dedicated infrastructure account that has a VPC

Infrastructure team must use this account to manage the network

Individual accounts cannot have the ability to manage their networks

Individual accounts must be able to create AWS resources within subnets

--------

Create a transit gateway  in the infrastructure account

Create a resource share in AWS Resource Access Manager in infrastructure account

Select the specfic AWS Organizations OU that will use the shared network

Select each subnet to associate with the resoruce share

============

Security engineer determined that existing application retreives credentials to an Amazon RDS for MySQL database from an encrypted file in Amazon S3

For the next version of application, the security engineer wants to implement following application design changes to improve security

- The database must use strong, randomly generated passwords stored in a secure AWS managed service
- Application resources must be deployed through AWS Cloud Formation
- Application must rotate database credentials for the database every 90 days


Solution architect will generate a Cloud Formation template to deploy application

Whcih resources specified in CloudFormation template will meet the security engineer's requirements with least amoutn of operational overhead

-------

Generate the database password as a SecureString parameter type using AWS Systems Manager Parameter Store

Create an AWS Lambda function resource to rotate database password

Specify a parameter store rotation schedule resource to rotoate the database password every 90 days

=======

Company is re-factoring its on-premises order-processing platform in AWS Cloud

Platform includes a web front-end that is hosted on a fleet of VMs, RabbitMQ to connect the front-end to the back-end, and a kubernetes cluster to run
a containerized backend system to process the orders

Company doesn't want to make any major changes to the application

Solution which meets these requirements with least over-head

-----

Create an AMI of the web server VM

Create an Amazon EC2 AutoScaling group that uses the AMI and an application load balancer

Setup Amazon MQ to replace the on-premises messaging queue

Configure Amazon Elastic Kubernetes service (Amazon EKS) to host the order-processing backend

===========

Company is creating a sequel for a popular online game

A large number of users from all over the world will play the game within the first week after the launch

Solutions architect needs to design a multi-region solution that will reduce latency, improve reliability, and require least effort to implement


-------

Create another S3 bucket in a new region, and configure s3 cross-region replication between the buckets

Create an Amazon CloudFront distribution and configure origin fail-over with two origins accessing the s3 bucket in each region

Configure DynamoDb global tables by enabling Amazon DynamoDB streams, and add a replica table in a new region

==========

Adventure company launches a new feature on its mobile app

Users can use the feature to upload their hiking and rafting photos and videos anytime

Photos and videos are stored in an s3 bucket and served through Aamzon CloudFront

Most of the uploaded photos and videos are accessed infrequently after 30 days

Implment a solution that maintains milli-second retrieval availability of the photos and videos at the lowest possible cost

-----

Configure an S3 life-cycle policy to transition image objects and video objects from s3 standard to s3 glacier deep archive after 30 days

=========

Company manages multiple AWS accounts by using AWS Organizations

Under the root OU: Research and Dataops

Because of regulatory requirements, all resources that the company deploys in the organization must reside in the ap-northeast-1 Region

Additionally, EC2 instances that company deploys in the data ops OU must use a pre-defined type of instance types

Solutions architect must implement a solution that applies these restrictions

Solution must maximize operational efficiency and must minimize ongoing maintenance

---------

Create an SCP

Use the aws:RequestedRegion condition key to restrict access to all AWS Regions except ap-northeast-1

Apply the SCP to the root OU

==========

Publishing company's design team updates the icons and other static assets that an e-commerce web application uses

Company serves the icons and assets from an amazon s3 bucket that is hosted in the company's production account

Company also uses a production account, that members of the design team can access

After the design team tests the static assets in the development account, design team needs to load the assets into the s3 bucket in production account

Solutiosn architect must provide design team with access to the production account without exposing other parts of the web application to the risk of unwanted changes

-----

In the production account, create a new IAM policy that allows read and write access to the S3 bucket

In the development account, create a role. Attach the new policy to the role. Define the production account as trusted entity.

In the development account, create a group that contains all the IAM users of the design team. Attach a different IAM policy to the group to allow the sts::AssumeRole action on the role in the production account

============

Company has an application that runs on Amazon EC2 instance

Solutions architect is designing VPC architecture in an AWS Region, where the application needs to access Amazon Aurora DB Cluster

EC2 instances are all associated with the same security group

DB Cluster is associated with its own security group

Solutions architect needs to add rules to the security groups to provide the application with least privilege access to DB Cluster

Which combination of steps will meet these requirements


--------

Add an inbound rule to the EC2 instance security group

Specify the DB Cluster's security group as the source  over the default Aurora port

-----

Add an outbound rule to the EC2 instance security group. Specify the DB cluster's security group as the desintation over the default Aurora port

===========

Advise a company on how to migrate its on-premises data processing application to the AWS Cloud

Currently users upload input files through a web portal

Web server stores the uploaded files on NAS and messages the processing server over a messaging queue

Each media file can take upto 1 hour to process

Company has determined that the number of media files awaiting processsing is significantly higher during business hours, with number of files rapidly declining after business hours

-------

Create a queue using Amazon SQS

Configure the existing web server to publish to the new queue

Use Amazon EC2 instances in an Auto-scaling group to pull requests from the queue and process the files

Scale the EC2 instances based on the SQS queue length

Store the processed files in an Amazon S3 bucket

=========

Company is using Amazon OpenSearch service to analyze data

Company loads data into an Open Search service cluster with 10 nodes from an Amazon S3 bucket that uses s3 standard storage

Data resides in the cluster for one  month for read-only analysis

After 1 month, company deletes the index that contains the data from the cluster

For compliance, company must retain a copy of all input data

Company is concerned about ongoing costs and asks a solution architect to recommend a new solution

------

Reduce the number of data nodes in the cluster to add Ultra Warm nodes to handle the expected capacity

Configure the indexes to transition to UltraWarm when OpenSearch service ingests the data

Transition the input data to S3 Glacier Deep Archive after 1 month by using an S3 lifecycle policy

=========


Company has deployed API that use Amazon API Gateway with Regional Endpoints

APIs call AWS Lambda functions that use API Gateway Authentication Mechanisms

After a design review, a solutions architect identifies a set of APIs that do not require public access

Solution architect design a solution to make the set of APIs accessible only from a VPC

All APIs need to be called with an authenticated user

----

Deploy lambda functions inside a VPC

Provision EC2 instance, and install an Apache Server

From the Apache server, call the lambda function

Use the internal CNAME record of the EC2 instance to call the API from VPC

=========

Company is planning to migrate 1000 on-premises servers to AWS

Servers run on several VMWare clusters in the company's data cetner

As part of migration plan, company wants to gather server metrics such as CPU details, RAM Usage, operating system infomration and running processes

Company wants to analyze and query the data

-----

Create a script ot automatically gather the server information from the on-premises hosts

use the AWS CLI to run the put-resource-attributes command to store the detailed server data in AWS Migration Hub

Query the data directly in the migration hub console

=========

Company uses webhooks to invoke functionality that runs in AWS Cloud
Company hosts webhook logic on a set of Amazon EC2 instances in an auto-scaling group that the company set as a target for a an applicaiton load balancer
Git Server calls the ALB for the configured Webhooks
Company wants to move the solution to a serverless architecture

-----

Deploy the webhook logic to AWS AppRunner
Create an ALB and set AppRunner as the target
Update the GitServers to call the ALB endpoint

========

A web application that uses an Amazon API Gateway Regional Endpoint and an AWS Lambda function
Consumers of web application are close to the AWS Region where application would be deployed

Lambda function only queries an Amazon Aurora MySQL database
Solutions Architect has configured the database to have three read-replicas

During testing the application doesnot meet performance requirements
Under high load, the application opens a large number of database connections

What actions solutions architect take to improve application performance

-------

Use RDS proxy to setup a connection pool to the reader endpoint of the Aurora database
Move the code for opening the database connection in the Lambda function outside of the event handler

=========

Employees can work from home by connecting through a VPN
Company is hosting internal applications with VPCs in multiple AWS accounts
Applications are accessible from the company's on-premises office network through an AWS site-to-site VPN connection
VPC in company's  main AWS account has peering connections established with VPCs in other AWS accounts

Design a scalable AWS Client VPN solution for employees to use while they work from home

-------

Create a Client VPN endpoint in the main AWS endpoint. Configure required routing that allows access to internal applications

=======

Health insurance company stores personally identifiable information in an Amazon S3 bucket
Company uses server side encryption with s3 managed encryption keys (SSE-S3) to encrypt the objects
According to new requirement, all current and future objects in s3 bucket must be encrypted by keys that company's security team manages
S3 bucket doesn't have versioning enabled

------

In the S3 bucket properties, change the default encryption to AES-256 with a customer managed key
Attach a policy to deny unencrypted PutObject requests to any entities that access the s3 bucket
Use the AWS CLI to re-upload all objects in the s3 bucket

=======

Company is running an application in AWS Cloud
Application collects and stores a large amount of un-structured data in an Amazon S3 bucket
S3 bucket contains several terabytes of data and uses s3 standard storage class
Data increases in size by several giga-bytes every day
Company needs to query and analyze data
Company doesn't need access data that is more than 1 year old. however all data must be retained indefinitely for compliance reason

-------

Use s3 Select to query the data
Create an S3 life-cycle policy to transition data that is more than 1 year old to S3 Glacier Deep Dive

========

Planning to migrate its business-critical applications from on-premises data center to AWS
Company has an on-premises installation of a Microsoft SQL server Always on Cluster
Company wants to migrate to an AWS managed Database service

Solutions architect must design a heterogenous database migration on AWS

----

Use the AWS Schema Conversion tool to translate the database schema to Amazon RDS for MySQL
Then use AWS Database migration service to migrate the data from on-premises database to Amazon RDS

=======

Finance company is running its business critical application on current generation Linux Ec2 instances
Application includes a self-managed MySQL database performing heavy I/O operations
Application is working fine to handle a moderate amount of traffic during the month

It slows down during the final three days of each  month due to month end reporting, even though company is using Elastic Load Balancer and Auto-Scaling within its infrastructure to meet the increased demand

-----

Peform a one-time migration of the database cluster to Amazon RDS, and creating several addtional read-replicas to handle the load during the month

========

Company has registered 10 new domain names

Company uses the domains for online marketing

Company needs a solution that will redirect online visitors to a specific URL for each domain

All domains and target URLs are defined in JSON document

All DNS records are managed by Amazon Route53

Solutions Architect must implement a redirect service that accepts HTTP and HTTPS requests

Which steps to take to implement these requirements with least amount of operational effort

------

Create an application load balancer that includes HTTP and HTTPS listeners

Create an AWS Lambda function that uses the JSON document in combination with the event message to look up and respond with a redirect URL

Create an SSL certificate by using AWS Certificate Manager. Include the domains as Subjective Alternative Names

============

Company is running critical application that uses an Amazon RDS for MySQL database to store data

The RDS DB instnace is deployed in Multi-Az mode

A recent RDS database failover test caused a 40 second outage to the application

Solutions Architect needs to design a solution to reduce the outage time to less than 20 seconds

-----

Use Amazon ElastiCache for Redis in front of the database

Use RDS proxy in front of the database

Create an RDS for MySQL read replica

=========

On-premises Active Directory Service for user-authentication

Use same authentication service to sign in to company's AWS account, which are using AWS Organizations

AWS site-to-site VPN connectivity already exists between on-premises environment and all the company's AWS accounts

Company's security policy requires conditional access  to the accounts based on user groups and roles

-------

In one of the company's AWS accounts, configure AWS Identity and Access Management (IAM) to use an OpenID Connect (OIDC) identity provider

Provision IAM roles that grant access to the AWS account for the federated users that correspond  to appropriate groups in Active Directory

Grant access to required AWS accounts by using cross-acount IAM roles

======

Company is using multiple AWS accounts

DNS records are stored in a private hosted zone for Amazon Route53 in Account A

Company's application and database are running in Account B

A Solutions Architect would deploy a two tier application in a new VPC

To simplify configuration, the db.example.com CNAME record set for the Amazon RDS endpoint was created in a private hosted zone for Amazon Route53

During deployment application failed to start

Troubleshooting revealed that db.example.com is not resolvable on the Amazon Ec2 instance

Solutions Architect confirmed that record set was created correctly in Route53

Combination of steps to resolve this issue

-----

Use SSH to connect to the application tier EC2 instance
Add and RDS endpoint IP address to the /etc/resolv.conf file

---

Create an authoriation to associate the private hosted zone in Account A with the new VPC in Account B

========

Company built an application based on AWS Lambda deployed in an AWS CloudFormation stack

Last production release of web application introduced an issue that resulted in an outage lasting several minutes

Solutions architect must adjust the deployment process to support a canary release

-----

Create an alias for every new deployed version of Lambda function

Use the AWS CLI update-alias command with the routing-config parameter to distribute the load

=======

Company is hosting a three-tier web application in an on-premises environment

Due to recent surge in traffic that resulted in downtime and significant financial impact, company management ordered that application be moved to AWS

Application is written in .Net and has a dependency on a MySQL database

Solutions Architect must design a scalable and highly available solution to meet the demand of 200,000 daily users

Designin an appropriate solution

-----

Use AWS Elastic Beanstalk to create an automatically scaling web server environment that spans two regions with an Application Load Balancer (ALB) in each region

Create a Multi-AZ deployment of an Amazon Aurora MySQL DB cluster with cross-Region read replica

Use Amazon Route53 with a geoproximity routing policy to route traffic between two regions

=========

Company is storing data in several Amazon DynamoDB tables
Solutions Architect must use a server-less architecture to make the data accessible publicly through a simple API over HTTPS
Solution must scale automatically in response to demands

-------

Create an Amazon API Gateway HTTP API

Configure this API with integrations to AWS Lambda functions that return data from the DynamoDB tables

------

Create an accelrator in AWS Global Accelerator

Configure this accelrator with AWS Lambda@Edge function integrations that return data from the DynamoDb tables

=========

Company wants to migrate its data analytics environment from on-premises to AWS

Environment consists of two simple Node.js applications

One application connects sensor data and loads it into a MySQL database

Other application aggregates data into reports

When aggregation jobs run, some of the load jobs fail to run correctly

Company must resolve the data loading issue

Company also needs migration to occur without interruptions or changes for the company's customers

------

Setup an Amazon Aurora MySQL database

Use AWS Database migration service to perform continuous data replication from the on-premises database to Aurora

Create an Aurora replica for the Aurora MySQL database, and move the aggregation jobs to run against the Aurora replica

Setup collection endpoints as AWS Lambda functions behind an application load balancer (ALB), and use Amazon RDS proxy to write to the Aurora MySQL database

When the databases are synced, point the collector DNS record to the ALB

Disable the AWS DMS sync task after the cutover from on premises to AWS

=======

Application runs on Amazon EC2 instances behind an ALB

Company uses an Amazon RDS DB instance as the database backend

Amazon CloudFront is configured with one origin that points to the ALB

Static content is cached

Amazon Route53 is used to host all public zones

After an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway)

The root cause is malformed HTTP headers that are returned to the ALB

Webpage returns successfully when a solutions architect reloads the web page immediately after the error occurs

Solutions architect needs to provide a custom error page instead of standard ALB error page to visitors

-------

Modify the existing Amazon Route53 records by adding health checks

Configure a fallback target if the health check fails

Modify DNS records to point to a publicly accessible web page

-------

Add a custom error response by configuring a CloudFront custom error page
Modify DNS records to point to a publicly accessible web page

=========

External audit of a company's serverless application reveals IAM policies that grant too many permissions

These policies are attached to the company's AWS Lambda execution roles

Hundred of company's Lambda functions have broad access permissions such as full access to Amazon S3 buckets and Amazon DynamoDB tables

Company wants each function to have only the minimal permissions that the function needs to complete its tasks

Solutions architect must determine which permission each Lambda function needs

--------

Turn on AWS CloudTrail logging for the AWS account

Use AWS Identity and Access Management access analyzer to generate IAM access poilicies based on the activity recorded in the CloudTrail

Review the generated policies to ensure that they meet the company's business requirements

=========

Company is using AWS CloudFormation to deploy its infrastructure

Company is concerned that, if a production Cloud Formation stack is deleted, important data stored in Amazon RDS databases or Amazon EBS volumes might also be deleted

How can company prevent users from accidently deleting data in this way

-------

Modify the Cloud Formation templates to add a DeletionPolicy attribute to RDS and EBS resources

==============

Company measured the application load and configured the RCUs and WCUs on the DynamoDB table to match the expected peak load

Peak load occurs once a week for a 4-hour period and is double the average load

Applicaiton load is close to average load for the rest of the week

Access pattern includes many more writes to the table than reads to the table

Implement a soltion to minimize the cost of the table

-----

Configure a DyanmoDB accelrator (DAX) in front of the table

Configure on-demand capacity mode for the table

=========

Multi-tier web application that runs on a fleet of Amazon Ec2 instances behind an Application Load balancer

Instances are in an auto-scaling group

ALB and Auto Scaling group are replicated in a backup AWS region

Minimum and Maximum value for the auto-scaling group are set to zero

Amazon RDS Multi-AZ DB instance stores the application's data

DB instance has a read-replica in backup region

Application presents an endpoint to end users by using an Amazon Route53 record

Company needs to reduce its RTO by less than 15 minutes by giving the applicaiton the ability to automatically failover to the backup region

Company doesn't have budget for active-active configuration

------

Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values

Configure Route53 with a health check that monitors the web application and sends an Amazon Simple Notification Service notification to the lambda function when the health check status is unhealhty

Update the application's Route53 record with a failover policy that routes traffic to the ALB in the backup region when a health check failure occurs

===========

Image processing service on AWS in VPC

VPC extends across two availability zones

Each availability zone contains two one public subnet and one private subnet

Service runs on Amazon EC2 instances in private subnets

Applicaiton load balancer in public subnets is in front of the service

Service needs to communicate with the internet and does so through two NAT gateways

Service uses Amazon s3 for image storage

Ec2 instances retreive approximately 1 TB of data from s3 bucket every day

Company has promoted the service as highly secure

-----

Setup an S3 gateway VPC endpoint in the VPC

Attach an endpoint policy to the endpoint to allow the required actions on the s3 bucket

========

Startup company hosts a fleet of Amazon Ec2 instances in private subnet using the latest Amazon Linux 2 AMI

Company's Engineers rely heavily on SSH access to the instances for troubleshooting

Company's existing architecture includes following

- A VPC with public and private subnets, and a NAT Gateway
- Site to Site VPN for connectivity with the on-premises environment
- EC2 security groups with direct SSH from the on-premises environment

Company' needs to increase security controls around SSH access and provide auditing of commands run by the engineers

------

Create an IAM role with the AmazonSSMManaged Instance Core managed policy

Attach the IAM role to all the EC2 instances

Remove all security group rules attached to the EC2 instances but allow inbound TCP on port 22

Have the engineers install the AWS Systems Manager Session Manager plugin for their devices and remotely access the instances by using the start-session API call from systems manager


Test # 6 
----------

========

A company uses AWS Organizations with a single OU named Production to manage multiple accounts

All accounts are members of the production OU

Administrators use deny list SCPs in the root of the organization to manage access to restricted services

Company recently acquired a new business unit and invited the new unit's existing AWS account to the organization

Administrators of the new business unit discovered that they are not able to update existing AWS Config rules to meet the company's policies

---------

Create a temporary OU named Onboarding for the new account

Apply an SCP to the Onboarding OU to allow AWS Config Actions

Move the new account to the Production OU when adjustments to the AWS Config are completed

===========

A financial company is planning to migrate its web application from on premises to AWS

Company uses third-party security tool to monitor the inbound traffic to the application

Company has used the security tool for the last 15 years, and tool has no cloud solutions available from its vendor

Company needs to use the security tool to inspect all packets that come in and out of VPC

This inspection must occur in real-time and must not affect the application's performance

Solution Architect must design a taret architecture on AWS that is highly available within an AWS region

---------

Deploy the security tool on EC2 instances in a new AutoScaling group in an existing VPC

Provision Gateway load balancer for each availability zone to redirect the traffic to the security tool

==========

Company recently implemented a centralized internal process for purchasing new Reservered Instances and modifying existing Reserved Instances

Process requires all business units that want to purchase or modify reserved instances to submit requests to a dedicated team for procurement

Solutions architect needs to enforce the new process in the most secure way possible

----

Ensure that all AWS accounts are part of an organization in AWS Organizations with all features enabled

Create an SCP that denies the ec2:PurchaseReservedInstancesOffering action and the ec2:ModifyReservedInstances action

Attach the SCP to each OU of the organization

========

Company is running an applicaiton in the AWS Cloud

Company's security team must approve the creation of all new IAM users

When a new IAM user is created, all access for the user must be removed automatically

Security team must then receive a notification to approve the user

Company has a multi-region AWS Cloud trail in the AWS account

Which combination of steps would meet the requirements

-------

Create an Amazon Event Bridge (Amazon CloudWatch Events) rule

Define a pattern with the detail type value set to AWS API call via CloudTrail and an event name of CreateUser

------

Invoke an AWS Step Functions state  machine to remove access

-----

Use Amazon Simple Notification Service to notify the security team

===========

A company is providing weather data over a REST-based API to several customers

API is hosted by Amazon API Gateway and is integrated with different AWS lambda function for each API operation

The company uses Amazon Route53 for DNS and has created a resource record of weather.example.com

Company stores data for the API in Amazon DynamoDB table

Company needs a solution that will give the API the ability to fail over to a different AWS Region

-------

Deploy a new API Gateway API and lambda functions in another region

Change the Route53 DNS record to a failover record

Enable target health monitoring

Convert the DyamoDB tables to global tables

=============

A company has an organization that has many AWS accounts in AWS organizations

A solution architect must improve how the company manages common security group rules for the AWS accounts in the Organization

Company has common set of IP CIDR ranges in an allow list in each AWS account, to allow access to and from the company's on-premises network

Developers within each account are responsible for adding new IP CIDR ranges to the security groups

Security team has its own AWS account

Currently, security team notifies the owners of the other AWS accounts when changes are made to the allow list

Design a solution that distributes the common set of CIDR ranges across all accounts

-----

Create a new Customer-managed prefix list in the security team's AWS account

Populate the customer managed prefix list with all internal CIDR ranges

Share the customer  managed prefix list with the Organization by using AWS Resource Access Manager

Notify the owner of each AWS account to allow the new customer-managed prefix list ID in their security groups

========

Financial services company in North America plans to release a new online web application to its customers on AWS

Company will launch the application in the us-east-1 region on Amazon EC2 instances

Application must be highly avaialble and must dyamically scale to meet user traffic

Company wants to implement a disaster recovery environment for the application in the us-west-1 region by using active-passive failover

------

Create a VPC in us-east-1 and a VPC in us-west-1

In the us-east-1 VPC, create an application load balancer, that extends across multiple availability zones in the VPC

Create an AutoScaling group that deploys the EC2 instances across multiple availability zones in us-east-1 VPC

Place the AutoScaling group behind the ALB

Setup the same configuration in the us-west-1 VPC

Create an Amazon Route53 hosted zone

Create separate records for each ALB

Enable health checks and configure a failover routing policy for each record

=============

A video processing company wants to build a machine learning model by using 600 TB of compressed data that is stored as thousands of files in the company's on-premises network attached storage system

Company doesn't have the necessary compute resources on-premises for ML experiments and wants to use AWS

Company needs to complete the data transfer to AWS within 3 weeks

Data transfere would be a one-time transfer

Data must be encrypted in transit

Measure upload speed of company's internet connection is 100 Mbps, and multiple departments share the connection

-------

Order several AWS Snowball Edge Storage Optimized devices by using the AWS Management Console

Configure the devices with a destination s3 bucket

Copy the data to the devices

Ship the devices back to AWS

=========

Company needs to implement a patching process for its server

On-premises servers and Amazon Ec2 instances use a variety of tools to perform patching

Management requires a single report showing the patch status of all the servers and instances

Which set of actions should the solutions archtiect take to meet these requirements

------

Use AWS Systems Manager to manage patches on the on-premises server and EC2 instances

Use system manager to generate patch compliance report

=========

Company wants to deploy an AWS WAF Solution to manage AWS WAF rules across multiple AWS accounts

Accounts are managed under different OUs in AWS Organizations

Administrators must be able to add or remove accounts or OUs from managed AWS WAF rule sets as needed

Administrators must have the ability to automatically update and remediate non-compliant AWS WAF rules in all accounts

Which solution meets these requirements with least over-head ....

-----

Use AWS Control Tower to manage AWS WAF rules across accounts in the organization

Use AWS Key Management Services (KMS) to store numbers or OUs to manage

Update AWS KMS as needed to add or remove accounts or OUs

Create IAM users in member accounts

Allow AWS Control Tower in the management account to use the access key and secret access key to create and update AWS WAF rules in member accounts

==========

Company has purchases appliances from different vendors

Appliances have IoT sensors

Sensors send status information in the vendor's proprietary formats to a legacy application that parses the information into JSON

Parsing is simple, but each vendor has a unique format

Once daily, the application parses all the JSON records and stores the JSON records in a relational database for analysis

Company needs to design a new data analysis solution that can deliver faster and optimize costs

-----

Create an AWS Transfer for SFTP server

Update the IoT sensor code to send the information as a .csv file through SFTP to the server

Use AWS Glue to catalog the files

Use Amazon Athena for analysis

=========

Company runs a Java application that has complex dependencies on VMs that are in the company's data center

Application is stable, but the company wants to modernize the technology stack

Company wants to migrate the application to AWS and minimize the administrative overhead to maintain the servers

Which solution will meet these requirements

-----

Migrate the application code to a container that runs in AWS lambda

Build an Amazon API Gateway REST API with lambda integration

Use API Gateway to interact with the application

=========

Company has software engineers spread across three teams

One of the three teams owns each application, and each time is responsible for the cost and performance of all its applications

Company wants to determine which costs on the AWS monthly bill are attributable to each application or team

Company must be able to create reports to compare costs from the last 12 months and to help forecast costs for next 12 months

Solutions Architect must recommend an AWS Billing and Cost Management Solution that provides these cost reports

--------

Enable Cost Explorer

Create a cost category for each applicaiton in billing and cost management

Activate teh user-defined cost-allocation tags that represent teh application and the team

============

Company wants to change internal cloud billing strategy

Cloud Governanc team shares reports for overall cloud spending with the head of each business unit

Company uses AWS Organziations to manage the separate AWS accounts for each business unit

Cloud Governance team wants a standardized solution so each business unit receives monthly reports on its cloud spending

Solution should also send notficiations for any cloud spending that exceeds the set threshold

-----

Configure AWS budgets in the organization's management account and configure budget alerts that are grouped by application, environment and owner

Add each business unit to an Amazon SNS topic for each alert

Use Cost Explorer in the organization's management account to create monthly reports for each business unit

===========

Company wants to use a third-party software as a service

Third party SaaS application also runs on AWS inside a VPC

Company will consume the third-party SaaS application from inside a VPC

No resources that run in the company VPC are allowed to be accessed from outside the company's VPC

All permission must confirm to the principles of least privilege

------

Create an AWS PrivateLink interface VPC endpoint

Connect this endpoint to the endpoint service that the third party SaaS application provides

Create a security group to limit the access to the endpoint

Associate the security group with the endpoint

==========

Building a solution in the AWS Cloud

Thousand of devices will connect to the solution and send data

Each device needs to be able to send and receive data in real time over the MQTT protocol

Each device must authenticate by using a unique X.509 certificate

Which solution meets these requirements with least overhead

---------

Setup an Amazon API Gateway HTTP API and a Network Load Balancer (NLB)

Create integration between API Gateway and the NLB

Configure a mutal TLS certificate authorizer on the HTTP API

Run an MQTT broker on an Amazon EC2 instance that the NLB targets

Connect each device to the NLB, via the HTTP API

==========

A company has many AWS accounts and uses AWS organizations to manage all of them

A solutions architect must implement a solution that the company can use to share a common network across multiple accounts

Company's infrastructure team has a dedicated infrastructure account that has a VPC

Infrastructure team must use this account to manage the network

Individual accounts cannot have the ability to manage their own networks

Individual accounts must be able to create AWS resoruces within subnets

-----

Create a transit gateway in the infrastructure account

Create a resource share in AWS Resource Access Manager in infrastructure account

Select the specific AWS Organization OU that will use the shared network

Select each subnet to associate with the resource share

===========

Company is hosting a mono-lithic REST-based API for a mobile app on five Amazon EC2 instances in public subnets of a VPC

Mobile clients connect to the API by using a domain name that is hosted on Amazon Route53

Company has created a Route53 multi-value answer routing policy with the IP addresses of all the EC2 instances

Recently, the app has been over-whelmed by large and sudden increases to traffic

App has not been able to keep up with the traffic

Solutions Architect needs to implement a solution that the app can handle the new and varying load

--------

Create an Application Load Balancer (ALB) in front of the API

Move the Ec2 instances to private subnets in the VPC

Add the EC2 instances as targets for the ALB

Update the Route53 record to point to the ALB

==========

Company migrated form processing applicaiton to AWS

Users upload scanned forms as files through a web application

Database stores user meta data and references to files that are stored in Amazon S3

Web application runs on Amazon EC2 instances and an Amazon RDS for PostgreSQL database

When forms are uploaded, application sends notification to a team through SNS

A team member then logsin and processe each form

Team member performs data validation on the form and extracts relevant data before entering the information into an other system that uses the API

Solutions architect needs to automate the manual processing of the form

Solution must provide accurate form extraction, mimimize time to market and minimize long-term professioanl over-head

-------

Extend the system with an application tier that uses AWS step functions and AWS lambda

Configure this tier to use Amazon Textact and Aamzon Comprehend to perform OCR on the forms when forms are uploaded

Store the output in Amazon S3

Parse this output by extracting the data, that is required within the application tier

Submit the data to the target system's API

=======

Serverless application that runs on AWS Lamdba function that is attached to a VPC

Company needs to integrate the application with a new service from an external provider

External provider supports only requests that come from public IPvr addresses that are in the allow list

Company must provide a single public IP address to the external provider before the application can start using the new service

Which solution will give the applicaiton the ability to access the new service

---------

Deploy an internet gateway

Associate an Elastic IP address with internet gateway

Configure the lambda function to use the internet gateway

================

Company runs serverless applicaiton in a single AWS Region

Applicaiton accesses external URLs and extract meta-data from these sites

Company uses an Amazon SNS topic to publish URLs to an Amazon Simple Queue Service (SQS) queue

An AWS Lambda function uses the queue as an event source and processes the URLs from the queue

Results are saved to an Amazon S3 bucket

Company wants to process each URL in other regions to compare possible differences in site localization

URLs must be published from the existing region

Results must be written to an existing S3 bucket in the current Region

Which combination of changes will produce multi-region deployment that meets these requirements

------

Subscribe the SQS queue in each Region to an SNS topic

Deploy the SQS queue with the Lambda function to other regions

============

Company runs an IoT platform on AWS

IoT sensors in various locations send data to the company's  Node.js API servers on Amazon Ec2 instances running behind an Application Load Balancer

Data is stored in an Aamzon RDS MySQL DB instance that uses a 4 TB General Purpose SSD volume

The number of sensors the company has deployed in the field has increased over time, and is expected to grow significantly

API Servers are consistently over-loaded and RDS metrics show high write-latency

Which steps will resolve the isues permanently and enable growth as new sensors are provisioned, while keeping the platform cost-efficient

-------

Leverage Amazon Kinesis Data Streams and AWS Lambda to ingest and process the raw data

Re-architect the database tier to use Amazon DynamoDB insteaf of an RDS MySQL DB instance

==========

Company is running several workloads in a single AWS account

A new company policy states that engineers can provision only approved resources and that engineers must use AWS CloudFormation to provision these resources

Solutions Architect needs to create a solution to enforce the new restrictions on the IAM role that the engineers use for access

------

Update the IAM policy for the engineers IAM role with permissions to only allow provisioning of approved resources and AWS Cloud formation

Use AWS Cloud Formation template to create stacks with approved resources

=========

Company is running an application on several Amazon EC2 instances in an Auto Scaling group behind an applicaiton load balancer

Load on application varies throughout the day, and EC2 instances are scaled in and out on regular basis

Log files from EC2 instances are copied to a central Amazon S3 bucket every 15 minutes

Security team discovers that log files are missing from some of the terminated EC2 instances

Which set of actions will ensure that log files are copied to the central s3 bucket from the terminated ec2 instances

-------

Create an AWS Systems Manager document with a script to copy log files to Amazon S3

Create an AutoScaling life-cycle hook and an Amazon Event bridge rule to detect lifecycle events from the auto scaling group

Invoke an AWS Lambda fucntion on the autoscaling:EC2_Instance_Terminating transition to call the AWS Systems Manager API SendCommand operation to run the document to ocpy the log files and send CONTINUE to the AutoScaling group to terminate the instance

===========

Solutions Architect has developed a web application that uses an Amazon API Gateway Regional Endpoint and an AWS Lambda function

Lambda function only queries an Amazon Aurora MySQL database

Under high-load the application opens a large number of database connections

Solutions Architect must improve the applicaiton's performance

------

Use RDS proxy to setup a connection pool to the reader endpoint of the Aurora database

Move the code for opening the database connection in the Lambda function outside of the event handler

===========

Company has 50 AWS accounts that are members of an organization in AWS Organizations

Each account contains multiple VPCs

Company wants to use AWS Transit Gateway to establish connectivity between the VPCs in each member account

Each time a new member account is created, company wants to automate the process of creating a new VPC and a transit gateway attachment

---------

From the management account, share the transit gateway with member accounts by using AWS Resource Access Manager

Launch an AWS CloudFormation stack set from the management account that automatically creates a new VPC and a VPC transit gateway attachment in a member account

Associate the attachment with the transit gateway in the management account by using the transit gateway

=========

Company runs a proprietary state less ETL application on an Amazon EC2 linux instance

Application is a Linux binrary and the source code cannot be modified

Applicaiton is single-threaded, uses 2 GB of RAM, and is highly CPU intensive

Application is scheduled to run every 4 hours and runs for upto 20 minutes

Solutions Architect wants to revise the architecture for the solution

------

Use AWS Fargate to run the application

Use Amazon EventBridge (Amazon CloudWatch Events) to invoke the task every 4 hours

===========

Video streaming company recently launched a mobile app for video sharing

App uploads various files to an Amazon S3 bucket in the us-east-1 region

the files range in size from 1 GB to 10 GB

users who access the app from Australia have experienced uplaods that take long periods of time

Sometimes the files fail to completely upload for these users

-----

Enable s3 transfer accelration on the s3 bucket

Configure the app to use the Transfer accelration endpoint for uploads

----

Confiure the app to break the video file into chunks

use a multi-part upload to transfer files to Aamzon S3


================

Solutions architect notices that the creation and subsequent termination of several large instance types account for high proportion of costs

Solution architect finds out that company developers are launching new Amazon Ec2 instance as part of their testing and are not using appropriate instance types

Solutions architect must implement a control mechanism to limit instance types that only developers can launch

-----

Create a new IAM policy

Specify the instance types that are allowed

Attach the policy to an IAM group that contains the IAM accounts for the developers

==============

Company has VPC flow logs enabled for its NAT gateway

Company is seeing Action = ACCEPT for inbound traffic that comes from public IP address 198.51.100.2, destined for a private Amazon Ec2 instance

Solutions architect must determine whether the traffic represents unsolicited inbound connections from the internet

First two octets of the VPC CIDR block are 203.0

Which steps should the solutions architect take to meet these requirements ?

---------

Open the Amazon CloudWatch console

Select the log group that contains the NAT gateway's elastic network interface and the private instance's elastic network interface and the private instance elastic network interface

Run a query to filter with the destination address set as "like 203.0"

Run the stats command to filter the sum of bytes transferred by the source address and the destination address

===========

Company has setup an AWS Direct Connect Connection in a central network account

Company expects to have hundreds of AWS accounts and VPCs in the near future

Corporate network must be able to access the resources on the AWS seamlessly and must also be able to communicate with the VPCs

Company also wants to route its cloud resources to the internet through its on-premises data center

-------

Create a direct connect gateway and a transit gateway in the central network account

Attach the transit gateway to the Direct Connect Gateway by using a transit

--------

Share the transit gateway with other accounts

-------

Provisions only private subnets. Open the necessary route on the transit gateway and customer gateway to allow outbound internet traffic from AWS to flow through NAT services that run in the data center

==========

Company with global offices has a single 1 Gbps AWS Direct Connect connection to a single AWS Region

Company's on-premises network uses the connection to communicate with the company's resources in the AWS Cloud

Connection has a single private virtual interface that connects to a single VPC

Solutions architect must implement a solution 
 - that adds a redundant Direct Connect Connection in the same region
 - Provide connectivity to other regions through the same pair of Direct Connect Connections as the company expands into other regions

------

Provision a direct connect gateway

Delete the existing private virtual interface from the existing connection

Create the second direct connect connection

Create a new private virtual interface on each connection, and connect both private virtual interfaces to the Direct Connect Gateway

Connect the Direct Connect Gateway to the single VP

=========

Company has recently completed the migration from on-premises data center to AWS Cloud by using a replatforming strategy

One of migrated servers is using a legacy simple mail transfer protocol (SMTP) service that a critical application relies upon

The application sends outbound email messages to the company's customers

Legacy SMTP server doesnot support TLS encryption and uses TCP port 25

Applicaiton can use SMTP Only

Company decided to use Simple Email Service (SES) and to decommission the legacy SMTP server

Company has created and validated the SES domain

Company has lifted the SES limits

----

Configure the application to connect to Amazon SES by using TLS Wrapper

Create an IAM role that has ses:SendEmail and ses:SendRawEmail permissions

Attach the IAM role to an Amazon EC2 instance

===========

Retail company is operating, its Ecommerce application on AWS

Application runs on Amazon EC2 instances behind an applicaiton load balancer (ALB)

Company uses an Amazon RDS DB instance as the database backend

Amazon CloudFront is configured with one origin that points to the ALB

Static content is cached, Amazon Route53 is used to host all public zones

After an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway error)

Root cause is malformed HTTP headers that are returned to the ALB

Webpage returns successfully when a solution architect reloads the web page, immediately after the error occurs

While the company is working on the problem,  a custom error page rather than  standard ALB error page is shown to visitors

------

Modify the existing Amazon Route53 records by adding health checks

Configure a fallback target if the health check fails

Modify the DNS record to point to a publicly accessible web page

-----

Add a custom error response by configuring a CloudFront custom error page

Modify DNS records to point to a publicly accessible web page

=========

Company is using multiple AWS accounts

DNS records are stored in a private hosted zone for Amazon Route53 in AccountA

Company's applications and databases are running in Account B

Solution's Architect would deploy a two tier application in a new VPC

To simplify the configuration, the db.example.com CNAME recordset for Amazon RDS endpoint was created in a private hosted zone for Amazon Route53

During deployment the application failed to start

Troubleshooting revealed that db.example.com is not resolvable on the Amazon Ec2 instance

Solution architect confirmed that the record set was created correctly in Route53

-------

Use SSH to connect to the application tier Ec2 instance
Add an RDS endpoint IP address to the /etc/resolv.conf file

-----

Create an authorization to associate the private hosted zone in Account A, with the new VPC in account

===========

Delivery company needs to migrate its third-party route planning application to AWS

Third party supplies a supported docker image from a public registry

The image can run in as many containers as required to generate the route map

Company has divided the delivery area into sections with supply hubs so that delivery drivers travel the shortest distance possible from the hubs to the customers

Company needs the ability to allocate resources cost-effectively based on the number of running containers

Which solution will meet these requirements with least operational overhead

--------

Create an Amazon Elastic Container Service (Amazon ECS) cluster on AWS Fargate

Use the AWS CLI run-task command and set enableECSManagedTags to true to launch the planning application

Use the --tags option to assign a custom tag to the task

==============

Company runs a new application as a static website in Amazon S3

Company has deployed the application to a production AWS account, and uses Amazon CloudFront to deliver the website

Website calls an Amazon API Gateway REST API

AWS Lambda function backs each API method

Company wants to create a CSV report every 2 weeks to show each API Lambda functions' recommended
- Configured Memory
- Recommended Cost
- Price difference between current configuraitons and recommendations

Company will store the reports in an S3 bucket

-------

Opt in to AWS Compute Optimizer

Create a lambda function that calls the ExportLambdaFunctionRecommendations Operations

Export the .csv file to an S3 bucket

Create an Amazon EventBridge rule to schedule the lambda function to run every 2 weeks

==========

Company is storing data on premises on a Windows File Server

Company produced 5 GB of new data daily

Company migrated part of its Windows based workload to AWS and needs the data to be available on a file system in the cloud

Company already has established an AWS Direct Connect connection between the On-Premises network and AWS

Which data migration strategy should the company use

-------

Use AWS DataSync to schedule a daily task to replicate data between the on-premises Windows file server and Amazon FSx

===========

Company has 10 accounts that are part of an Organization in AWS Organizations

AWS config is configured in each account

All account belong either to the Prod OU or NonProd OU

Company has setup an Amazon Event Bridge rule in each AWS account to notify an Amazon Simple Notification Service (Amazon SNS) topic

When an Amazon EC2 security group inbound rule is created with a 0.0.0.0/0 as the source

Company's security team is subscribed to the SNS topic

For all accounts in non-prod OU, security team needs to remove the ability to create a security group inbound rule that includes 0.0.0.0/0 as the source

which solution meets this requirement with least operational overhead

-------

Configure an SCP to allow the ec2:AuthorizeSecurityGroupIngres action, when the value of aws:SourceIp condition key is 0.0.0.0/0

Apply the SCP to NonProd OU

=======

Company is developing a new service that will be accessed using TCP on a static port

Solutions Architect must ensure that the service is 

- highly available
- redundancy across availability zones
- Accessible using the DNS name my.service.com, which is publicly accessible
- must use fixed address assignments so other companies can add the addresses to their allow lists

Assuming that resources are deployed in multiple Availability Zones in a single Region, which solution will meet these requirements

--------

Create Amazon EC2 instance for the service

Create one ElasticIP address for each availability zone

Create a Network Load Balancer (NLB) and expose the assigned TCP port

Assign the Elastic IP addresses to the NLB for each Availability Zone

Create a target group and register the EC2 instances with the NLB

Create a new A (alias) record set named my.service.com, and assign the NLB DNS name to the record set

========

Company has an applicaiton that runs on Amazon EC2 instances

Solutions Architect is designing VPC infrastructure in an AWS region where the application needs to access an Amazon Aurora DB Cluster

EC2 instances are all associated with the same security group

DB Cluster is associated with its own security group

Solutions architect needs to add rules to the security group to provide application with least privilege access to DB Cluster

Which steps would meet these requriements ?

-----

Add an inbound rule to the EC2 instance's security group. Specify the DB Cluster's security groups as the source over the default Aurora port


-----

Add an outbound rule to the EC2 instance's security group. Specify the DB Cluster's security group as the destination over the default Aurora port

==========

Solutions Architect is designing a data storage and retreival architecture for a new application

Applicaiton is designed to ingest millions of small records per minute from devices all around the world

Each record is less than 4 KB in size and needs to be stored in a durable location, where it can be retreived with low latency

Data is ephemeral and company is required to store the data for 120 days only, after which the data can be deleted

Solutions Architect calculates that during the course of an year, storage requirements would be 15-20 TB

Which storage capacity is most cost-effective

--------

Design the application to store each incoming record in an Amazon DynamoDB table properly configured for the scale

Configure the DynamoDB Time to Live (TTL) feature to delete records older than 120 days


===============

Company has created an OU in AWS Organizations for each of its engineering teams

Each OU owns multiple AWS accounts

Organization has hundreds of AWS accounts

Solutions Architect must design a solution so that each OU can view a break-down of usage costs across its AWS accounts

-----

Create an AWS Cost and Usage Report (CUR) from the AWS Organizations managment account

Allow each team to visualize the CUR through an Amazon Quick Sight Dashboard

===========

AWS partner company is building a service in AWS Organizations using its organization named org1

This service requires the partner company to have access to AWS resources in a customer account, which is in a separate organization named org2

Company must establish least privilege security access using an API or command line tool to the customer account

What is most secure way to allow org1 to access resources in org2

------

The customer should create an IAM role and assign the required permission to the IAM role

Partner company should then use the IAM role's Amazon Resource Name (ARN), including the external ID in the IAM role's trust policy, when requesting access to perform the required tasks

===========

Company is hosting a critical application on a single Amazon EC2 instance

Application uses an Amazon ElastiCache for Redis single-node cluster for an in-memory data store

Application uses an Amazon RDS for MariaDb DB instance for a relational database

For the infrastructure to function, each peace of the infrastructure must be healthy and must be in active state

Solution Architect needs to improve the applications architecture so that infrastructure can automatically recover from failure with the least possible downtime

Which combination of steps would meet these requirements

-------

Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances

Ensure that EC2 instances are part of an AutoScaling group that has a minimum capacity of two instances

------

Modify the DB instance to create a Multi-AZ deployment that extends across two availability zones

Create a replication group for the ElastiCache for Redis Cluster. Enable Multi-AZ on the cluster

========

Company is hosting ecommerce website across multiple AWS regions

Company wants the website to be operational at all times for online purchases

Website stores data in Amazon RDS for MySQL DB instance

which solution provides highest availability

-----

Configure read replicas on Amazon RDS

In case of disruption, promote a cross-region and read replica to be a standalone DB instance

Direct database traffic to be promoted to DB instance

Create a replacement read replica that has promoted DB instance as its source

========

Company is building a software as a service solution on AWS

Company has deployed an Amazon API Gateway REST API with AWS Lambda integration in multiple AWS regions and in same production account

Company offers tiered pricing that gives customers the ability to pay for the capacity to make a certain number of API calls per second

Premium tier offers upto 3000 calls per second, and customers are identified by a unique API key

Premimum tier customers report that they receive error responses of 429, Too Many Requests, from multiple API method during peak usage hours

Logs indicate that the Lambda function is never invoked

Cause of error message for these customers

--------

The company reached its API Gateway account limit for calls per second

===========

Application is using an Amazon RDS for MySQL Multi-AZ DB instnace in the us-east-1 region

After a failover test, application lost connection to the database and could not re-establish the connection

After restart of application, the application re-established the connections

Solutions Architect must implement a solution so that application can re-establish connections to the database without requiring a restart

which solution would meet these requirements

-------

Create an RDS proxy

Configure the existing RDS endpoint as a target

Update the connection settings in the application to point to the RDS proxy endpoint

==========

Company has its Cloud Infrastructure on AWS

Solutions Architect needs to define the infrastructure as code

Infrastructure is currently deployed in one AWS Region

Company's business expansion plan includes deployments in multiple regions across multiple AWS accounts

What solutions architect should do to meet these ?

--------

Use AWS Organizations and AWS CloudFormation StackSets

Deploy a Cloud Formation template from an account that has the necessary IAM permissions

========

Web application fetches data from a third-party API that is behind a firewall

Third party accepts only one public CIDR block in each client's allow list

Customer wants to migrate their web application to AWS Cloud

Application would be hosted on a set of Amazon EC2 instances behind an Application Load Balancer (ALB) in a VPC

Solutions architect to ensure that the web application can continue to call the third party API after the migration

------

Register a block of customer-owned public IP addresses in the AWS account

Create Elastic IP addresses from the address block and assign them to NAT gateways in VPC

=========

Company consists of two separate business units

Each business unit has its own AWS account with a single organization in AWS Organizations

Business units regularly share sensitive documents with each other

To facilitate sharing, company created an Amazon S3 bucket in each account and configured low-way replication between the s3 buckets

S3 buckets have millions of objects

Recently, a security audit idnetified that neither S3 bucket has encryption at rest enabled

Company policy requires that all documents must be stored with encryption at rest

Company wants to implement server-side encryption with Amazon S3 managed encryption keys (SSE-S3)

What is most operationally efficient solution that meets these requirements

-------

Turn on SSE-S3 on both s3 buckets

Encrypt the existing objects by using an S3 copy command in the AWS CLI

===========

Retail company


Company wants to be able to route network traffic from it's on-premises infrastructure into VPC in either of these Regions

Company also needs to support traffic that is routed directly between VPCs in those Regions

No single point of failure can exist on the network

Company already has created two 1 Gbps AWS Direct Connect Connections from its on-premises data center

Each connection goes into a separate Direct Connect location in Europe for high-availability

Two locations are named DX-A and DX-B respectively

Each region has a single AWS Transit Gateway that is configured to route all inter-VPC traffic within that Region

------

Create a private VIF from the DX-A connection into a Direct Connect gateway

Create a private VIF from the DX-B connection into the same Direct Connect gateway for high availability

Associate both the eu-west-1 and us-east-1 transit gateways with the Direct Connect Gateways

Peer the transit gateways with each other to support cross-Region routing

=========

Company is planning to host a web application on AWS and wants to load balance the traffic across a group of EC2 instances

One of the security requirements is to enable end-to-end encryption in transit between the client and the web server

Which solution meets these requirements

------

Place the EC2 instance behind an Application Load Balancer (ALB)

Provision an SSL certificate using AWS Certificate Manager (ACM), and associate the SSL certificate with the ALB

Provision a third party SSL certificate and install it on each EC2 instance

Configure the ALB to listen on port 443 and to forward traffic to port 443 on the instances

========

Company's solution archtiect is reviewing a web applicaiton that runs on AWS

Application references static assets in an Amazon S3 bucket in the us-east-1 region

Company needs resiliency across multiple AWS regions

Company has already created an S3 bucket in a second region

Which solution meets these requirements with least overhead

-------

Configure replication on the s3 bucket in us-east-1 to replicate objects to s3 bucket in the second region

If failover is required, update the application code to load s3 objects from the s3 bucket in the second region

=========

Example Corp has an on-premises data center and a VPC named VPC A in the Example Corp AWS account

On-premises network connects to a VPC A through an AWS site-to-site VPN

On-premises server can properly access VPC A

Example Corp just acquired any company, which has a VPC named VPC B

There is no IP address overlap among these networks

Example Corp has peered VPC A and VPC B

Example Corp wants to connect from its on-premises server to VPC B

Example Corp has properly setup the network ACL and security groups

-----

Modify the site to site VPNs virtual private gateway definition to include VPC A and VPC B

Split the two routers of the virutal private gateway between the two VPCs


===========

Monolithic application that is critical to company's business

Company hosts the application on an Amazon EC2 instnace that runs Amazon Linux 2

Company's application team receives a directive from the legal department to backup the data from from the instance's encrypted Amazon Elastic Block Store (EBS)
volume to an Amazon S3 bucket

Application team doesn't have the administrative SSH key pair for the instance

Application must continue to serve the users

-------

Attach a role to the instance with permission to write to Amazon S3

Use the AWS System Manager Session Manager option to gain access to the instance and run commands to copy data into Amazon S3

==========

Solutions Architect needs to copy data from an Amazon S3 bucket in an AWS account to a new S3 bucket in a new AWS account

Solution Architect must implement a solution that uses the AWS CLI

Which combination of steps will successfully copy the data

------

Run the aws s3 sync command as a user in the destination account

Specify the source and the destination buckets to copy the data

-----

Create an IAM policy in the destination account

Configure the policy to allow a user in the destination account to list contents and get objects in the source bucket, and to list contents, put objects,
and set objectACLs in the destination bucket

Attach the policy to the user

----------

Create a bucket policy to allow the source bucket to list its contents and to put objects and set Object ACLs in the destination bucket

Attach the bucket policy to the destination bucket

==============

Video processing company has an application that downloads images from an Amazon S3 bucket, process the images, stores a transformed image in a second s3 bucket, and updates metadata about the image in an Amazon DynamoDb table

Application is writtne in Node.js and runs by using an AWS Lambda function

Lambda function is invoked when a new image is uploaded to Amazon s3

Application ran without incident for a while. However, size of images has grown significantly. Lambda function is now failing frequently with timeout errors. The function timeout is set to its maximum value.

Solutions Architecture needs to refactor the application's architecture to prevent invocation failures

Company doesnot want to manage the underlying infrastructure

------

Modify the application to store images on Amazon Elastic File System (Amazon EFS) and to store meta data on an Amazon RDS Db instance

Adjust the lambda function to mount the EFS file share

-------

Create a new Amazon Elastic Container Service (ECS) task definition with a compatibility type of Amazon Ec2

Configure the task definition to use the new image in Amazon Elastic Container Registry (Amazon ECR)

Adjust the Lambda function to invoke an ECS task by using the ECS task definition when a new file arrives in Amazon S3

===========

Company needs to architect a hybrid DNS solution

Solution would use an Amazon Route53 private hosted zone for the domain cloud.exmple.com for the resources stored within the VPC

Company has the following DNS resolution requirements:

- On-premises systems should be able to resolve and connect to cloud.example.com
- All VPCs should be able to resolve cloud.example.com

There is already an AWS Direct Connect Connection between the on-premises corporate network and AWS Transit Gateway

Which architecture would meet these requirements with highest performance

--------

Assocaite the private hosted zone to the shared services VPC

Create a Route53 inbound resolver in the shared services VPC

Attach the shared services VPC to the transit gateway and create forwarding rules in the on-premises DNS server for cloudexample.com that point to the inbound resolver

==========

Company wants to improve the security posture of the application and plans to use AWS WAF web ACLs

Solution must not adversely affect legitimate traffic to the application

------

Set the action of the Web ACL rules to Count

Enable AWS WAF logging analyze the requests for false positives

Modify the rules to avoid any false positives over time

Change the action of the web ACL rules from Count to Block

========

Company is running a critical applicaiton that uses an Amazon RDS for MySQL database to store data

RDS DB instnace is deployed in Multi-AZ mode

Recent RDS database failover test caused a 40 second outage to the application

Solution Architect needs to reduce the outage time to less than 20 seconds

Which steps to solution architect should take to meet these requirements

------

Use Amazon ElatiCache for Redis in front of the database

Use RDS proxy in front of the database

Create an RDS for MySQL read replica

===========

Company runs a content management application


Solution Architect must design a solution that joins all the instances that run the application to an Active Directory Domain

Solution also must implement Windows ACL to control access to file contents

Application always must maintain exactly the same content on all running instances at any given point in time

Which solution will meet these requirements with least management overhead

-------

Create a new AMI from the current EC2 instance that is running

Create an Amazon FSx for Lustre file system

Create an Auto-Scaling group that extends across three availability zones and maintains a minimum size of three instances

Implement a user data script to join the instance to the AD domain and mount the FSx for Lustre file system

=============

Company plans to refactor a mono-lithic application into a modern application design deployed on AWS

The CI/CD pipeline needs to be upgraded to support the modern design for the application with the following requirements
- It should allow changes to be released several times every hour
- It should be able to roll backs the changes as quickly as possible


----

Specify AWS Elastic beanstalk to stage in a secondary enviornment as the deployment target for the CI/CD pipeline of the application

To deploy, swap the staging and production environment URLs

==============

Company is running a data-intensive application on AWS

Application runs on a cluster of hundreds of Amazon EC2 instances

Shared file system also runs on several EC2 instances that store the 200 TB of data

Application reads and modifies the data on the shared file system and generates a report

The job runs once monthly, reads a subset of the files from the shared file system, and takes about 72 hours to complete

Compute instances scale in an Auto Scaling group, but the instances that host the shared file system run continuously

Solutions Architect needs to reduce costs by replacing the shared file system instances

File System must provide high performance access to the needed data for the duration of the 72 hour run

Which solution will provide the LARGEST overall cost reduction while meeting these requirements

-------

Migrate the data from the existing shared file system to an Amazon S3 bucket

Before the job runs each month, use AWS Storage Gateway to create a file gateway, with the data from Amazon s3

Use the file gateway as the shared storage for the job

Delete the file gateway when the job is completed

==============

Company has an environment that has a single AWS account

Solutions Architect is reviewing the environment to recommend what the company could improve specifically in terms of access to the AWS management console

Company's IT support workers currently access the console for administrative tasks, authenticating with named IAM users that have been mapped to their job role

IT support workers no longer want to maintain both their Active Directory and IAM user accounts

They want to be able to access the console by using their existing Active Directory Credentials

Solution Architect is using AWS IAM Identity Center (AWS Single Sign On) to implement this functionality

-------

Create an Organization in AWS Organization

Turn on all feature for the organization

Create and configure an AD connector to connect to the company's on-premises Active Directory

Configure IAM Identity Center and set the AD Connector as the identity source

Create permission sets and map them to existing groups within the Company's Active Directory


===============

Solutions architect is auditing the security group or an AWS Lambda function for a company

Lambda function retrieves latest changes from an Amazon Aurora database

Lambda function and database run in the same VPC

Lambda environment variables are providing the database credentials to the Lambda function

Lambda function aggregates data and makes the data available in an Amazon S3 bucket that is configured for server side encryption with AWS KMS managed encryption keys (SSE-KMS)

Data must not travel the internet

If any database credentials become compromised, the company needs a solution that minimizes the impact of the compromise

-----

Save the database credentials in AWS Secrets Manager

Setup password rotation on the credentials in Secrets Manager

Change the IAM role for the Lambda Function to allow the function to access secrets manager

Modify the Lambda function to retrieve the credentials from secrets manager

Enforce HTTPS on the connection to Amazon S3 during data transfers

===========

Company uses Amazon S3 to store file and images in a variety of storage classes

Company's s3 costs have increased substantially during the past year

A solutions archtiect needs to review data trends for the past 12 months and idnetify the appropriate storage class for the objects

Which solution would meet these requirements

---------

Use S3 storage class analyses

Import data trends into an Amazon Quicksight dashboard to analyze storage trends

===============

Company has multiple AWS accounts in using AWS Organizations

Company's AWS accounts host VPCs, Amazon EC2 instances and containers

Company's compliance team has deployed a security tool in each VPC where the company has deployments

The security tools run on EC2 instances and send information to the AWS account that is dedicated for the compliance team

The company has tagged all the compliance-related resources with a key of "CostCenter" and a value of "Compliance"

Company wants to identify the cost of the security tools that are running on the EC2 instances so that the company can charge the compliance teams' AWS account

----------

In the management account of the organization, activate the cost center user-defined tags

Configure monthly AWS cost and usage reports to save to an Amazon S3 bucket in the management account

Use the tag breakdown in the report to obtain the total cost for the costCenter tagged resourcess


===============

Solutions Architect is investigating an issue in which a company cannot establish new sessions in Amazon Workspaces

An initial analysis indicates that the issue involves user profiles

Amazon Workspaces environment is configured to use Amazon FSx for Windows file server as the profile share storage

The FSx for windows file server file system is configured with 10 TB of storage

Solutions Architect discovers that the file system has reached its maximum capacity

Solutions Architect must ensure that the users can regain access

Solution must also prevent the problem from occuring again

---------

Monitor the file system by using the FreeStorageCapacity metric in Amazon CloudWatch

Use AWS Step Functions to increase the capacity as required

================

Company is storing data in several Amazon DynamoDB tables

Solutions Architect must use a serverless architecture, to make the data accessible publicly through a simple API over HTTPS

Solution must scale automatically in response to demand

-------

Create an accelerator in AWS Global Accelerator. Configure this accelerator with AWS Lambda@Edge function integrations that retrun data from DynamoDB tables

Create an Amazon API Gateway HTTP API. Configure this API with integrations to AWS Lambda functions that return data from the DynamoDB table

================

Company that uses AWS Organizations allows developers to experiment on AWS

As part of the landing zone that the company has deployed, developers use their company email address to request an account

Company wants to ensure that developers are not launching costly services or running services un-necessarily

Company must give developers a fixed monthly budget to limit their AWS cost

-------

Use AWS Budgets to create a fixed monthly budget for each develop's account as part of the account creation process

Create an IAM policy to deny access to costly services and components

Apply an IAM policy to the developers accounts

---------

Create an AWS Budgets alert action to send an Amazon Simple Notification Service (SNS) notfication when the budgeted amount is reached

Invoke an AWS Lambda fucntion to terminate all services

================

Software company has deployed an applicaiton that consumes a REST API by using Amazon API Gateway

Applicaiton is showing an increase in the number of errors during PUT requests

Most of the PUT calls come from a small number of clients that are authenticated with specific API keys

Solutions architect has identified that a large number of PUT requests originate from one client

API is non-critical, and clients can tolerate retries of un-successful calls

However, errors are displayed to customers and are causing damage to the APIs reputation

-------

Implementing API throttling through a usage plan at the API Gateway level

Ensure that the client application handles code 429 replies without error

================

Company's existing architecture includes the following
- A VPC with private and public subnets, and a NAT gateway
- Site-to-Site VPN for connectivity with the on-premises environment
- EC2 security groups with direct SSH access from the on-premises environment

Company needs to increase security controls around SSH access and providing auditing of commands runs by engineers

--------

Create an IAM role with the AmazonSSMManagedInstanceCore managed policy attached
Attach the IAM role to all of the EC2 instances

Remove all security group rules attached to the EC2 instances that allow inbound TCP on port 22

Have the engineers install the AWS Systems Manager Session Manager plugin for their devices and remotely access the instances by using the start-session API call from the Systems Manager

================

Company recently acquired several other companies

Each company has a separate AWS account with a different billing and reporting method

Acquiring company has consolidated all the accounts into one organization in AWS Organizations

Acquiring company has found it difficult to generate a cost report that contains meaningful groups for all the teams

Acquiring company's finance team needs a solution to report on costs for all the companies through a self-managed application

--------

Use the AWS Price List Query API to collect account spending information

Create a specialized template in AWS Cost Explorer that the finance department will use to build reports

=============

Company has applications in AWS account that is named Source

The account is in an Organization in AWS Organizations

One of the application uses AWS lambda functions and stores inventory data in an Amazon Aurora database

Applicaiton deploys the lambda functions by using a deployment package

Company has configured automated backups for Aurora

Company wants to migrate the Lambda functions and the Aurora database to a new AWS account that is named Target

Application processes critical data, so the company must minimize downtime

Which solution would meet these requirements

----------

Use AWS Resource Access Manager (AWS RAM) to share the Lambda functions and the Aurora DB cluster with the target account

Grant the target account permission to clone the Aurora DB cluster

=============

Test # 7 


=============

Company wants to migrate its on-premises database to AWS Cloud

The CTO at the company wants a solution that can handle complex database configurations such as secondary indexes, foreign keys, and stored procedures

As solutions architect, which of the following AWS services should be combined to handle this use case

-------

AWS Schema Conversion Tool

AWS Database Migration Service

==============

Computer Vision Researchers at a University are trying to optimize the I/O bound processes for a proprietary algorithm running on EC2 instances

Ideal storage would facilitate high-performance IOPS when doing file processing in a temporary storage space before uploading the results back into Amazon S3

As solutions architect, which of the following AWS Storage Options would you recommend as the MOST performant as well

------

Use EC2 instances with Instance store as the storage option


================

Company has application running on Amazon EC2 instances in a VPC

One of the application needs to call an Amazon S3 API to store and read objects

Companies security policies restrict any internet-bound traffic from the application

--------

Create an S3 bucket in a private subnet

================

Multi-National company is looking at optimizing their AWS resources across various countries and regions

Understand the best-practices on cost-optimization, performance and security for their systems architecture spanning across multiple business units

-------

AWS Trusted Advisor

================

Checking the workload on some of your General Purpose (SSD) and provisioned IOPS (SSD) volumes, and it seems that the I/O latency is higher than you require

You should probably check the ...... to make sure that your application is not trying to drive more IOPS than you have provisioned

-------

Average queue length

================

An IT company has built a custom data warehousing solution for a retail organization by using Amazon Redshift

As part of the cost optimization, the company wants to move any historical data (any data older than one year) into s3, as the daily analytical reports consume data for just the last one year

Analysts want to retain the ability to cross-reference this historical data along with the daily reports

Company wants to develop a solution with the least amount of effort and MINIMUM cost

As solutions architect, which option to facilitate this use case

--------

Use Redshift Spectrum to create RedShift clusters tables pointing to the underlying historical data in s3

The analytics team can then query this historical data in s3

The analytics team can then query this historical data to cross-refernce with the daily reports from RedShift

================

IT Company has built a custom data warehousing solution for a retail organization by using Amazon Redshift

As part of the cost optimization, the company wants to move any historical data (any data older than a year) into s3, as the daily analytical reports consume data for just the last one year

Analysts want to retain the ability to cross-reference this historical data along with the daily reports

Company wants to develop a Solution with the least amount of effort and MINIMUM cost

As solutions architect, which option would you recommend to facilitate this use case

------

Use Redshift spectrum to create RedShift Cluster tables pointing to the underlying historical data in S3

The analytics team can then query this historical data to cross-refernce with the daily reports from RedShift

================

Big Data analytics company wants to setup an AWS Cloud architecture that throttles requests in case of sudden traffic spikes

Company is looking for AWS services that can be used for buffering or throttling to handle such traffic variations

---------

Amazon API Gateway, Amazon SQS and Amazon Kinesis

================

CloudFront offers a multi-tier cache in the form of regional edge caches that improve latency

There are certain content types that bypass the regional edge caches, and go directly to the origin

Which of the following content types skip the regional edge caches

-------

Proxy methods PUT/POST/PATCH/OPTIONS/DELETE go directly to the origin

Dynamic content, as determined at request time (cache-behavior configured to forward all headers)

================

Large financial institution operates an on-premises data center with hundreds of PB of data managed on Microsoft's Distributed File System (DFS)

CTO wants the organization to transition into a hybrid cloud environment and run data-intensive workloads that support DFS

Which of following AWS Services can facilitate the migration of these workloads

----------

Amazon FSx for Windows File Server

================

Your company has created a datawarehouse using RedShift that is used to analyze data from s3

From the usage pattern, you have detected that after 30 days, the data is rarely queried in RedShift and its not 'hot data' any more

You would like to preserver the SQL querying capability on your data and get the queries started immediately

You want to adopt a pricing model that allows you to save the maximum amount of cost on RedShift

---------

Move the data to S3 standard IA after 30 days

Analyze the cold data with Athena

================

Solutions Architect is designing an application on AWS that uses persistent block storage

Data must be encrypted at Rest

Which solution meets these requirements

--------

Encrypt Amazon EBS volumes on Amazon EC2 instances

================

Legacy application is built using a tightly coupled monolithic architecture

Due to increase in number of users, application performance has de-graded

Company now wants to decouple the architecture and adopt AWS microservices architecture

Some of these micro-services need to handle fast running processes whereas other micro-services need to handle slower processes

Right option to connect to these micro-services

--------

Configure Amazon SQS queue to decouple microservices running faster processes from the microservices running slower ones

================

Software engineering intern at a company is documenting the features offered by EC2 spot instances, Spot Blocks and Spot Fleets

Can you help the intern by selecting the correct options that identify key characteristics of these three types of spot instances

-------

A spot fleet is a set of Spot Instances and optionally On-Demand Instances that are launched to meet your target capacity

Spot blocks allow you to request Amazon EC2 spot instances for 1 to 6 hours at a time to avoid being interrupted

-------

Spot instances are spare Ec2 capacity that can save you up 90% off of On-Demand Prices

Spot instances can be interrupted by Amazon EC2 for capacity requirements with a 2-minute notification

================

Company runs multiple windows workloads on AWS

Company's employees use Windows File Shares that are hosted on two Amazon Ec2 instances

The file shares syncronize data between themselves and maintain duplicate copies

Company wants a highly avaialable and durable storage solution that preserves how users currently access the files

What should solutions architect do to meet these requirements

-------

Extend the file share environment to Amazon FSx for windows file server with a Multi-AZ configuration

Migrate all the data to FSx for windows file server

================

What is true about RDS read replicas encryption

-----

If the master database is encrypted, the read replicas are encrypted

================

You need to import several hundred mega-bytes of data from a local Oracle database to an Amazon RDS DB instance

What does AWS recommend you use to accomplish this

-----

Oracle Data Pump

================

What does this CloudFormation snippet do

 SecurityGroupIngress: - IpProtocol: tcp FromPort: 80 ToPort: 80 CidrIp: 0.0.0.0/0 - IpProtocol: tcp FromPort: 22 ToPort: 22 CidrIp: 192.168.1.1/32

-----

It allows any IP to pass through on the HTTP port

It configures a security group's inbound rules

It lets traffic flow from one IP on port 22

================

Application hosted on AWS is experiencing performance problems

Application vendor wants to perform an analysis of the log file to troubleshoot further

Log file is stored on Amazon s3 and is 10 GB in size

Application owner will make the log file available to the vendor for a limited time

MOST secure way to do this

-----

Generate a pre-signed URL and have the vendor download the log file before it expires


================

Solutions Architect is designing an application that uses Amazon EBS volumes

Volumes must be backed up to a different region

How should solution architect meet this requirement

-----

Create EBS snapshots and then copy them to the desired region

================

Company is using a SQL database to store movie data that is publicly accessible

Database runs on an Amazon RDS Single-AZ DB instance

A script runs queries at random intervals each day to record the number of new movies that have been added to the database

The script must report a final total during business hours

Company's development team notices that the database performance is in-adequate for development tasks when the script is running

Solutions architect must recommend a solution to resolve this issue

Which solution will meet this requirement with least over-head

-----

Use Amazon ElastiCache to cache the common queries that the script runs against the database

================

A client notices that their engineers often make mistakes when creating Amazon SQS queues for their backend systems

Which action should solutions architect recommend to improve this process

-----

Use AWS Cloud Formation templates to manage the Amazon SQS queue creation

================

Media streaming company collects real-time data and stores it in a disk-optimized database system

Company is not getting the expected throughput and wants an in-memory database storage solution that performs faster and provides high availability using data replication

-----

Amazon Elasticache for Memcached

================

Company delivers files in Amazon S3 to certain users who do not have AWS credentials

These users must be given access for a limited time

What should solutions architect do to securely meet these requirements

-----

Generate a pre-signed URL to share with the users

================

Engineering team at an e-commerce company wants to migrate from SQS Standard queues to FIFO queues with batching

As solutions architect, which of following steps would you have in the migration checklist

-----

Make sure that the name of the FIFO queue ends with a .fifo suffix

Delete the existing standard queue and recreate it as a FIFO queue

Make sure that the throughput for the target FIFO queue doesn't exceed 3,000 messages per second

================

To support critical production workloads that require  maximum resiliency, company wants to configure network connections between its Amazon VPC and the on-premises infrastructure

Company needs AWS Direct Connect connections with speeds greater than 1 Gbps

As solutions architect, which of the following will you suggest as the best architecture for this requirement

-----

Opt for two separate Direct Connect connections terminating on separate devices in more than one Direct Connect location

================

Company runs a legacy application with a single-tier architecture on an Amazon EC2 instance

Disk I/O is low, with occasional small spikes during business hours

Company requires the instance to be stopped from 8 PM to 8 AM daily

Which storage option is most appropriate for this workload

-----

Amazon s3

================

Telecom company operates thousands of hardware devices like switches, routers, cables etc.

Real-time status data for these devices must be fed into a communications application for notifications

Simultaneously, another analytics application needs to read the same real-time status data and analyze all the connecting lines that may go down because of any device failure

As solutions architect, which of the following solutions would you suggest, so that both the applications can consume the real-time status data concurrently

-----

Amazon Kinesis Data Streams

================

You are working as a solutions architect for a photo processing company that has a proprietary algorithm to compress an image without any loss in quality

Because of the efficiency of the algorithm, your clients are willing to wait for a response that carries their compressed images back

You also want to process these jobs asynchronously and scale quickly, to cater to the high demand

You want the job to be retried in case of failures

Which combination of choices do you recommend to minimize cost and comply with the requirements

-----

Amazon Simple Queue Service (SQS)

EC2 Spot instances

================

Company is developing a healthcare application that cannot afford any downtime for database write operations

Company has hired you as an AWS Certified Solutions Architect Associate to build a solution using Amazon Aurora

Which of the following options would you recommend

-----

Setup an Aurora multi-master DB cluster

================

Solutions Architect has created a new AWS account and must secure AWS account root user access

Which combination of actions will accomplish this

-----

Enable multi-factor authentication to the root user

Add the root user to a group containing administrative permissions

Apply the required permissions to the root user with an inline policy document

================

Engineering team at an e-commerce company has been tasked with migrating to a serverless architecture

Team wants to focus on the key points of consideration when using Lambda as backbone for this architecture

As a solutions architect, which of the following options would you identify as correct for the given requirement

-----

If you intend to reuse code in more than one Lambda function, you should consider creating a Lambda layer for the re-usable code

-----

Since lambda functions can scale extremely quickly, its a good idea to deploy a CloudWatch Alarm that notifies your team, when function metrics such as ConcurrentExecutions or Invocations exceeds the expected threshold

-----

By default, Lambda functions always operate from an AWS owned VPC and hence have access to any public internet address or public AWS APIs

Once a lambda function is VPC-enabled, it will need a route through a NAT gateway in a public subnet to access public resources

================

Company is deploying a new public web application to AWS

This application will run behind a load balancer (ALB)

Application needs to be encrypted at the edge with an SSL/TLS certificate that is issued by an external certificate authority (CA)

Certificate must be rotated each year before the certificate expires

What should solutions architect do to meet these requirements

-----

Use AWS Certificate Manager (ACM) to import an SSL/TLS certificate

Apply the certificate to the ALB

Use Amazon Event Bridge (Amazon CloudWatch Events) to send a notification when the certificate is nearing expiration

Rotate the certificate manually

================

IT department at a consulting firm is conducting a training workshop for new developers

As part of the evaluation exercise on Amazon S3, the new developers were asked to identify the invalid storage class lifecycle transitions for objects stored on s3

Can you spot the INVALID lifecycle transitions from the options below

-----

S3 One Zone-IA => S3 Standard-IA

S3 Intelligent-Tiering => S3 Standard

================

A company uses DynamoDB as a data store for various kinds of customer data, such as user profiles, user events, clicks and visited links

Some of these use-cases require 
	- a high request rate (millions of requests per second)
	- low predicatable latency
	- reliability

Company now wants to add a caching layer to support high read volumes

As a solutions architect, which of the following services would you recommend as a caching layer for this use-case

-----

Elasti Cache

DynamoDB Accelrator (DAX)

================

Company wants to run its critical applications in containers to meet requirements for scalability and availability

Company wants to focus on maintenance of critical applications

Company doesn't want to be responsible for provisioning and managing the underlying infrastructure that runs the containerized workloads

-----

Use Amazon Elastic Container Service (ECS) on AWS Faragate

================

Company wants to run its critical applications in containers to meet for scalability and availability

Company wants to focus on maintenance of critical applications

Company doens't want to be responsible for provisioning and managing the underlying infrastructure that runs the containerized workloads

-----

Use Amazon Elastic Container Service (ECS) on AWS Fargate

================

Silicon valley startup uses AWS Cloud for its IT infrastructure

Engineering team needs to implement an archival soltuion based on Amazon s3 Glacier to enforce regulatory and compliance controls on data access

-----

Use S3 Glacier Vault to store the sensitive archived data and then use a vault lock policy to enforce compliance controls

================

Database backend for retail company website is hosted on Amazon RDS for MySQL having a primary instance and three read replicas to support read scalability

Company has mandated that read replicas should lag no more than 1 second behind primary instance to provide the best possible user experience

Read replicas are falling further behind during periods of peak traffic spikes, resulting in bad user experience as the searches produce inconsistent results

You have been hired as an AWS Certified Solutions Architect to reduce the replication lag as much as possible with minimal changes to applicaiton code or the effort required to manage the underlying resources

-----

Setup database migration from RDS MySQL to Aurora MySQL

Swap out the MySQL read replicas with Aurora Replicas

Configure Aurora AutoScaling

================

Configuring security groups for their two-tier applicaiton with public web servers and private database servers

Team wants to understand the allowed configuration options for an inbound rule for a security group

As soltuions architect, which of following would you identify as an INVALID option for setting up such configuration

-----

You can use an Internet Gateway ID as the custom source for the inbound rule

================

Perform some maintenance work on a specific EC2 instance that is part of AutoScaling group using a step scaling policy

Team facing a maintenance challenge, every time the team deploys a maintenance patch, the instance health check status shows as out of service for a few minutes

This causes an AutoScaling group to provision another replacement instance immediately

As solution architect which are most time/resource efficient steps that you would recommend so that the maintenance work can be completed at the earliest

-----

Suspend the ReplaceUnhealthy process type for the Auto Scaling group and apply the maintenance patch to the instance

Once the instance is ready, you can manually set the instance's health status back to healthy and activate the ReplaceUnhealthy process type again


-----

Put the instnace into the Standby state and then update the instance by applying the maintenance patch

Once the instance is ready, you can exit the Standby state and then return the instance to service

================

Small enterprise to an enterprise employing over 1000 people

As team has grown, company has observed some strange behavior, with s3 settings being changed regularly

How can you figure out whats happending without restricting the rights of users


-----

Use CloudTrail to analyze API calls

================

Pharma company developing vaccine for covid-19 virus
Researches want to process the reference health-care data in a highly available as well as HIPAA compliant in-memory database that supports SQL query caching
ElastiCache for Redis/Memcached

-----

ElastiCache for Redis/Memcached

================

Company has deployed its consumer focused, web application on EC2 based web servers and use RDS PostGreSQL DB as the data store

PostGreSQL DB is setup in a private subnet that allows inbound traffic from selected EC2 instances

Which of following steps secures access to database

-----

Configure RDS to use SSL for data in transit


================

Company's cloud architect has setup a solution that uses Route53 to configure the DNS records for the primary website with the domain pointing to the Application Load Balancer

Company wants a solution where users will be directed to a static error page, configured as backup, in case of unavailability of primary website

Which configuration will meet the company's  requirements while keeping the changes to bare minimum

-----

Setup a Route-53 active-passive type of failover routing policy

If Route-53 health check determines the ALB endpoint as unhealthy, the traffic will be diverted to a static error page, hosted on Amazon S3 bucket

================

Retail company has connectd its on-premises data center to the AWS Cloud via AWS Direct Connect

Company wants to be able to resolve DNS queries for any resources in the on-premises network from the AWS VPC and also resolve any DNS queries for AWS VPC from on-premises network

As Solutions Architect, which of the following can be combined to address the given use-case

-----

Create an outbound endpoint on Route53 Resolver and then Route53 Resolver can conditionally forward queries to resolvers on the on-premises network via this endpoint

Create an inbound endpoint on Route53 Resolver and then DNS resolvers on the on-premises network can forward DNS queries to Route53 Resolver via this endpoint


================

Solutions Architect is designing a three-tier web application

Architect wants to restrict access to the database tier to accept traffic from the application servers only

These application servers are in an auto-scaling group and may vary in quantity

-----

Configure the database network ACL to deny all inbound non-database traffic from the application-tier subnet

================

Engineering team at a social media company has noticed, while some of messages stored in s3 are frequently accessed, 
other sit idle for a considerable span of time

What is your recommendation to build the most Cost-effective solution

-----

Store the images using S3 intelligent-tiering storage class

================

Video analytics organziation has been acquired by a leading media company

Analytics organizaion has 10 independent applications, with an on-premises data footprint of about 70 TB for each application

CTO of media company has set a timeline of two weeks to carry out the data migration from on-premises data center to AWS Cloud and establish connectivity

Which of following are cost-effective options for completing data transfer and establishing connectivity

-----

Order 10 Snowball edge storage optimized devices to complete the one-time data transfer

Setup site-to-site vpn to establish on-going connectivity between the on-premises data center and AWS cloud


================

Solutions Architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not traverse the internet

What should solutions architect do to accomplish this

-----

Create a route table entry for the endpoint

Create an ENI for the endpoint in each of the subnets of the VPC. Create a security group entry in the default security group to provide access

================

Junior scientist working with Deep Space Research Laboratory at NASA is trying to upload a high-resolution  image of nebula into Amazon S3

Image size is approximately 3 GB

Junior Scientist is using s3 transfer accelration (s3ta) for faster image upload

S3TA doesn't result in accelrated transfer

Given this, what is correct about the charages of this image transfer

-----

The junior scientist doesnt need to pay any charges for the image upload

================

You have been hired to work with engineering team at a company to create REST API using the serverless architecture

Which of following solutions will you recommend to move the company to serverless architecture

-----

API Gateway exposing Lambda functionality

================

Which of following is true regarding cross-zone load balancing as seen in Application Load Balancer versus Network Load Balancer

-----

By default, cross-zone load balancing is enabled for Application Load Balancer and disabled for Network Load Balancer

================

Company doesn't want to spend time managing and rotating the keys, but it does want to control who can access these keys

What should solutions architect do to accomplish this

-----

Server-Side encryption with AWS KMS-Managed keys (SSE-KMS)

================

In context of AWS Support, why must an EC2 instance be unreacable for 20 minutes rather than allowing customers to open tickets immediately

-----

Beacuse most reahability issues are resolved by automated processes in less than 20 minutes

================

Ride sharing company wants to improve the ride-tracking system that stores GPS Cooridinates for all rides

Engineering team at the company is looking for a NoSQL database that has single-digit milli-second latency, can scale horizontally and is server-less

So they can perform high-frequency lookups reliably

As Solutions Architect, which database do you recommend for their requirements

-----

Amazon DynamoDB

================

Solutions Architect is designing network architecture for an application that has compliance requirements

Application would be hosted on Amazon EC2 instances in a private subnet and will be using Amazon S3 for storing data

Compliance requirements mandate that the data cannot traverse the public internet

What is MOST secure way to satisfy this requirement

-----

Use a VPC endpoint

================

Developed a new REST API leveraging the API Gateway, AWS Lambda and Aurora Database service

Most of the workload on the website is read-heavy

Data rarely changes and it is acceptable to server users outdated data for about 24 hours

Recently, the website has been experiencing high load and the costs incurred on the Aurora database have been very high

How can you easily reduce the costs while improving performance, with minimal changes

-----

Enable API Gateway Caching

================

Weather forecast agency collects key weather metrics across multiple cities in the US and sends the data in the form of key-value pairs to AWS Cloud at a one-minute frequency

As a Solutions Architect, which of the following AWS Services would you use to build a solution for processing and then reliably storing this data with high availability

-----

DynamoDB

Lambda

================

Company recently launched Linux-based application instances on Amazon EC2 in a private subnet and launched a linux based bastion host on an Amazon EC2 instance in a public subnet of a VPC

Solution Architect needs to connect from the on-premises network, through the company's internet connection, to the bastion host and to the application servers

Solutions Architect must make sure that security groups of all EC2 instances will allow that access

Which combination of steps would solutions architect take to meet these requirements

-----

Replace the current security group of the bastion host with one that only allows inbound access from the external IP range for the company

Replace the current security group of the application instances with one that allows inbound SSH access from only the private IP address of the bastion host

================

Company recently launched Linux-based application instances on Amazon EC2 in a private subnet and launched a Linux Based Bastion host on an Amazon EC2 instance in a public subnet of a VPC

Solutions Architect needs to connect from the on-premises network, through the company's internet connection, to the bastion host, and to the application servers

-----

Replace the current security group of the bastion host with one that only allows inbound access from the external IP range of the company

Replace the current security group of the application instances with one that allows inbound SSH access from only the private address of the bastion host

================

Application generates audit logs of operational activities

Compliance requirements mandate that the application retain the logs for 5 years

How can this requirement be met

-----

Save the logs in an Amazon Glacier Vault and use the Vault lock feature

================

Engineering team at a social media company wants to use Amazon CloudWatch alarms to automatically recover EC2 instances if they become impaired

Team has hired you as a Solutions Architect to provide subject matter expertise

-----

If your instance has a public IPv4 address, it retains the public IPv4 address after recovery

A recovered instance is identical to the original instance, including the instance ID, private IP addresses, Elastic IP addresses, and all instance meta-data

================

Company needs to configure a real-time data ingestion architecture for its application

Company needs an API, a process that transforms data as the data is streamed and a storage solution for the data

Which solutions would meet these requirements with the LEAST operational overhead

-----

Configure the Amazon API Gateway API to send data to an Amazon Kinesis Data Stream

Create an Amazon Kinesis Data Firehose delivery stream that uses the Kinesis Data Stream as a data source

Use AWS Lambda functions to transform the data

Use the Kinesis Data Firehose delivery stream to send the data to Amazon S3

================

IT Company wants to review its security best practices after an incident was reported where a new developer on the team was assigned full access to DynamoDB

Developer accidently deleted a couple of tables from the production environment while building out a new feature

Which is the MOST effective way to address this issue so that such incidents do not occur

-----

Use permissions boundary to control the maximum permissions employees can grant to the IAM principals

================

A developer has configured inbound traffic for the relevant ports in both the Security Group of the EC2 instance as well as Network Access Control List (NACL) of the subnet for the EC2 instance

Developer is, however, unable to connect to the service running on the Amazon Ec2 instance

As a solutions architect, how will you fix this issue

-----

Security Groups are stateful, so allowing inbound traffic to the necessary ports enables the connection

Network ACLs are stateless, so you must allow both inbound and outbound traffic

================

Development team has deployed a micro-service to the ECS

Application layer is in a Docker container that provides both static and dynamic content through an Application Load Balancer

With increasing load, the ECS Cluster is experiencing high network usage

Development team has looked into network usage and found that 90% of it is due to distributing static content of the application

-----

Distribute the static content through Amazon S3

================

IT Consultant is helping a small business revamp their technology infrastructure on the AWS Cloud

The business has two AWS accounts and all resources are provisioned in the us-west-2 region

IT Consultant is trying to launch an EC2 instance in each of the two AWS accounts such that the instances are in the same Availability zone of the us-west-2 region

Even after selecting the same default subnet (us-west-2a), while launching the instances in each of the AWS accounts, IT consultant notices that availability zones are still different

-----

Use AZ ID to uniquely identify the availability zones across the two AWS accounts

================

Startup has just developed a video backup service hosted on a fleet of EC2 instances

EC2 instances are behind an application load balancer and the instances are using EBS volumes for storage

The service provides authenticated users the ability to upload the videos that are then saved on the EBS volume attached to a given instance

On first day of beta launch, users start complaining that they can only see some of the videos in their uploaded videos backup

Everytime the users log into the website, they claim to see a different subnet of their uploaded videos

-----

Mount EFS on all EC2 instances. Write a one time job to copy the videos from all EBS volumes to EFS

Modify the application to use EFS for storing the videos

================

Consider the following policy associated with an IAM group containing several users : 

{
   "Version""":""2012-10-17"",
   "Id""":""EC2TerminationPolicy"",
   "Statement""":[
      {
         "Effect""":"""Deny""",
         "Action""":"""ec2":"*""",
         "Resource""":"""*""",
         "Condition""":{
            "StringNotEquals""":{
               "ec2":"Region""":""us-west-1
            }
         }
      },
      {
         "Effect""":"""Allow""",
         "Action""":"""ec2":"TerminateInstances""",
         "Resource""":"""*""",
         "Condition""":{
            "IpAddress""":{
               "aws":"SourceIp""":""10.200.200.0/24
            }
         }
      }
   ]
}

-----

Users belonging to the IAM group can terminate an EC2 instance in the us-west-1 region when the user's source IP is 10.200.200.200

================

Solutions architect needs the static website within an Amazon S3 bucket

Which action will accomplish this

-----

Enable Amazon S3 versioning

================

Retail company wants to establish encrypted network connectivity between its on-premises data center and AWS Cloud

Company wants to get the solution up and running in the fastest possible time and it should also support encryption in transit

As Solutions Architect, which of the following solutions would you suggest the company

-----

Use Site-to-Site VPN to establish encrypted network connnectivity between the on-premises data center and AWS Cloud

================

Company has noticed several provisioned throughput exceptions on its DynamoDB database due to major spikes in the writes to the database

Development team wants to decouple the application layer from the database layer and dedicate a worker process to writing the data to DynamoDB

Which middle-ware do you recommend on using that can scale infinitely and meet these requirements

-----

Amazon Simple Queue Service (SQS)

================

Company uses Amazon S3 buckets for storing sensitive customer data

Company has defined different retention periods for different objects present in the Amazon S3 buckets, based on the compliance requirements

But the retention rules do not seem to work as expected

Which of the following options represent a valid configuration for setting up retention periods for objects in Amazon S3 buckets

-----

When you apply a retention period to an object version explicitly, you specify a retain until date for the object version

Different versions of a single object can have different retention modes and periods

================

Copmany has several web servers that need to frequently access a common RDS MySQL Multi-AZ DB instance

Company wants a secure method for the web servers to connect to the database while meeting a security requirement to rotate user credentials frequently

-----

Store the database user credentials in AWS Secrets Manager

Grant the necessary IAM permissions to allow the web servers to access AWS Secrets Manager

================

System Administration team has a requirement to run certain custom scripts only once during the launch of the Amazon EC2 instances that host their application

Which of following represents the best way of configuring a solution for this requirement

-----

Run the custom scripts as user data scripts on the Amazon Ec2 instances

================

Company hires experienced specialists to analyze the customer service calls attended by its call center reprsentatives

Now the company wants to move to AWS Cloud and is looking at an automated solution to analyze customer service calls for sentiment analysis and security

As Solutions Architect, which of the following solutions would you recommend

-----

Use Amazon Transcribe to convert audio files to text and Amazon Athena to understand the underlying customer sentiments

================

Company has on-premises servers running a relational database

Current database serves high read traffic for users in different locations

Company wants to migrate to AWS with the least amount of effort

Database solution should support disaster recovery and not affect the company's current traffic flow

-----

Use a database in Amazon RDS with Multi-AZ and atleast one read replica

================

Development team at an e-commerce startup has setup multiple micro-services running on Ec2 instances under an Application Load Balancer

Team wants to route traffic to multiple back-end services based on the URL paths of the HTTP header

So it wants requests for https://www.example.com/orders to go to a specific micro-service and requests for https://www.example.com/products to go to another microservice

Which of the following features of Application Load Balacner can be used for this use-case

-----


8888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888888

Test # 8
----------



Path-Based routing

================

Solution Architect is designing a new service behind Amazon API Gateway

Request patterns for the service will be un-predictable and can change suddenly from 0 requests to over 500 per second

Total size of data that needs to be persisted in database is currently less than 1 GB with un-predictable future growth

Data can be queried using simple key-value requests

Which combination of AWS services would meet these requirements

-----

Amazon DynamoDB

================

Application hosted on Amazon EC2 instance contains sensitive personal information about all its customers and needs to be protected from all types of cyber-attacks

Company is considering using the AWS Web Application Firewall to handle this requirement

Identify correct solution leveraging capabilities of WAF

-----

Create a CloudFront distribution for the application on Amazon EC2 instances

Deploy AWS WAF on Amazon CloudFront to provide the necessary safety measures

================

Financial services company has a web application that serves users in the United states and Europe

Application consists of a MySQL database tier and a web tier

Database tier consists of a MySQL database hosted in us-east-1

Amazon Rout53 geoproximity routing is used to direct traffic to instances in the closest region

Performance review of system reveals that European users are not receiving the same level of query performance as those in United States

-----

Deploy MySQL instances in each Region

Deploy an application load balancer in front of MySQL to reduce the load on the primary instance

================

Engineering lead is designing a VPC with public and private subnets

VPC and subnets use IPv4 CIDR blocks

There is one public subnet and one private subnet in each of three availability zones (AZs) for high-availability

Internet gateway is used to provide internet access for the public subnets

Private subnet requires access to the internet to allow EC2 instances to download software updates

Which of following options represents the correct solution to setup internet access for the private subnet

-----

Setup three NAT Gateways, one in each public subnet in each AZ. Create a custom route table for each AZ that forwards non-local traffic to the NAT Gateway in its AZ

================

Company has production workload that runs on 1,000 Amazon EC2 linux instances

Workload is powered by third-party software

Compnay needs to patch the third-party software on all EC2 instances as quickl as possible to remediate a critical security vulnerability

What should solutions architect do to meet these requirements

-----

Use AWS Systems Manager Run Command to run a custom command that applies the patches to all EC2 instances

================

Company is hosting a website behind multiple Application Load Balancers

Company has different distribution rights for its content around the world

Solution Architect needs to ensure that users are served the correct content without violating distribution rights

-----

Configure Amazon Route53 with a geo-location policy

================

Engineering team at a retail company manages 3 Amazon EC2 instnaces that make read-heavy requests to the Amazon RDS for the PostGreSQL DB instance

As an AWS Certified Solutions Architect Associate, you have been tasked to make the database instance resilient from a disaster recovery perspective

Which of following features will help you in disaster recovery of the database

-----

Enable the automated backup feature of Amazon RDS in a multi-AZ deployment that creates backups across multiple Regions

Use cross-region Read Replicas

================

Engineering team at an in-home fitness company is evaluating multiple in-memory data stores with the ability to power its on-demand, live leaderboard

Company's leaderboard requires  high-availability, low latency and real-time processing to deliver customizable user data for the community of users working out together virtually from the comfort of thier home

As Solutions Architect, which of following solution would you recommend

-----

Power the on-demand, live leader-board using ElastiCache Redis as it meets the in-memory, high-availability, low latency requirements

Power the on-demand, live leader-board using DynamoDB with DynamoDB Accelrator (DAX) as it meets the  in-memory, high-availability, low latency requirements

================

Company has a legacy application that processes data in two parts

Second part of the process takes longer than the first, so the company has decided to re-write the application as two micro-services running on Amazon ECS that can scale independently

How should solutions architect integrate the micro-services

-----

Implement code in micro-service 1 to send data to Amazon Kinesis Data Firehose

Implement code in micro-service 2 to read data from Amazon Kinesis Data Firehose

================

Company runs an internal browser-based application

Application runs on an Amazon EC2 instances behind an Application Load Balancer

Instances run in an Amazon EC2 AutoScaling group across multiple availability zones

AutoScaling group scales upto 20 instnaces during work hours, but scales to 2 instances over night

Staff complaints that the application is very slow when the day begins, although it runs well by mid-morning

How should the scaling be changed to address the staff complaints and keep costs to a minimum

-----

Implement a target trackign action at a lower CPU threshold, and decrease the cool-down period

================

DevOps team at a multi-national company is helping its subsidiaries standardize EC2 instances by using the same Amazon Machine Image (AMI)

Some of these subsidiaries are in the same AWS region but use different AWS accounts whereas others are in different AWS regions but use the same AWS account as the parent company

DevOps team has hired you as the solution architect for this project

Which of following would you regard as correct regarding the capabilities of AMIs

-----

Copying an AMI backed by an encrypted snapshot cannot result in an unencrypted target snapshot

You can share an AMI with another AWS account

You can copy an AMI across AWS regions

================

Developers are creating a new online transaction processing (OLTP) applicaiton for a small database that is very read-write intensive

A single table in the database is updated continuously throughout the day, and the developers want to ensure that the database performance is consistent

Which EBS storage option will achieve the MOST consistent performance to help maintain application performance


-----

Provisioned IOPS SSD

================

Amazon EC2 AutoScaling needs to terminate an instance from Availability Zone (AZ) us-east-1a as it has the most number of instances among the AZs being used currently

There are 4 instances in the AZ us-east-1a like so: 

	Instance A has the oldest launch template
	Instance B has the oldest launch configuration
	Instance C has the newest launch configuration
	Instance D is closest to the next billing hour

-------

Instance B

================

Solution Architect is designing the cloud architecture for a new application being deployed on AWS

Process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed

Processor application is stateless

Solutions Architect must ensure that the application is loosely coupled and job items are durably stored

Which design should the solutions architect use

-------

Create an Amazon SQS queue to hold the jobs that needs to be processed

Create an Amazon Machine Image (AMI) that consists of the processor application

Create a launch template that uses the AMI

Create an AutoScaling group using the launch template

Set the scaling policy for the AutoScaling group to add and remove nodes based on the number of items in the SQS queue

================

Online gaming company wants to block access to its application from specific countries

Company wants to allow its remote development team (from one of the blocked countries) to have access to the application

Application is deployed on EC2 instances running under an ALB with AWS WAF

As Solutions Architect, which of following solutions can be combined to address the given use-case

-------

Use WAF geo match statement listing the countries that you want to block

Use WAF IP set statement that specifies the IP addresses that you want to allow through

================

CRM company has a SaaS application that feeds to other in-house and third-party applications

The SaaS application and the in-house applications are being migrated to use AWS services for this inter-application communication

As solutions architect, which of the following would you suggest to asynchronously decouple the architecture

-------

Use Amazon EventBrdige to decouple the system architecture

================

Health-care company manages its web application on Amazon EC2 instances running behind Auto Scaling Group

Company provides ambulance for critical patients and needs the application to be reliable

Workload of the company can be managed on 2 Ec2 instances and can peak up to 6 instances when traffic increases

As solution architect, which of the following configurations would you select as the best fit for these requirements

-------

The ASG should be configured with a minimum capacity set to 4, with 2 instances each in two different availability zones

The maximum capacity of the ASG should be set to 6

================

Global pharmaceutical company wants to move most of the on-premises data into Amazon S3, EFS, FSx for Windows File Server, easily quickly and cost-effectively

As Solutions Architect, which of the following Solutions would you recommend as the BEST fit to automate and accelrate online data transfers to these AWS storage services

-------

Use AWS DataSync to automate and accelrate online data transfers to the given AWS storage services

================

A company has historically operated only in the us-east-1 region and stores encrypted data in s3 using SSE-KMS

As part of enhancing its security posture as well as improving the backup and recovery architecture, the company wants to store the encrypted data in S3 that is replicated into the us-west-1 AWS region

Security policies mandate that the data must be encrypted and decrypted using the same key in both AWS regions

-------

Create a new S3 bucket in the us-east-1 region with replication enabled from this new bucket into another bucket in us-west-1 region

Enable SSE-KMS encryption on the new bucket in us-east-1 region by using an AWS KMS multi-region key

Copy the existing data from the current s3 bucket in us-east-1 region into this new s3 bucket in the us-east-1 region

================

Company needs to store its accounting records in Amazon S3

Records must be immediately accessible for 1 year and then must be archives for an additional 9 years

No one at the company, including administrative and root users, can be able to delete the records during the entire 10 year period

Records must be stored with maximum resiliency

What solutions would meet this requirement

-------

Use an S3 Life Cycle policy to transition the records from s3 standard to s3 glacier deep archive after 1 year

Use s3 object lock in compliance mode for a period of 10 years


================

NFS volume

-----

Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3

================

Solutions Architect is designing a new hybrid architecture to extend a company's on-premises infrastructure to AWS

Company requires a highly available connection with consistent low latency to an AWS region

Company needs to minimize costs and is willing to accept slower traffic if the primary connection fails

-----

Provision an AWS Direct Connect connection to a region

Provision a VPN connection as a backup if the primary Direct Connect Connection fails

================

Company hosts a popular web application

Web application connects to a database running in a private VPC subnet

Web servers must be accessible only to customers on an SSL connection

RDS MySQL database server must be accessible only from the web servers

How should solutions architect design a solution to meet the requirements without impacting running applications

-----

Open an HTTPS port on the security group for web servers and set the source to 0.0.0.0/0

Open the MySQL port on the database security group and attach it to the MySQL instance

Set the source to web server security group

================

As solutions architect, you have setup a database on a single EC2 instance that has an EBS volume of type gp2

You currently have 300 gb of space on the gp2 device

EC2 instance is of type m5.large

Database performance has been poor and upon looking at CloudWatch, you realize that IOPS on the EBS volume is maxing out

-----

Convert the gp2 volume to an io1

================

Financial services company has a web application that serves users in the United States and Europe

Application consists of a database tier and a web server tier

Database tier consists of a MySQL database hosted in us-east-1

Amazon Route53 geoproximity routing is used to direct traffic to instances in the closest Region

A performance review of the system reveals, that european users are not recieving the same level of query performance as those in the United states

-----

Migrate the database to an Amazon Aurora global database in MySQL compatibility mode

Configure read replicas in one of the European regions

================

Company captures click stream data from multiple websites and analyzes it using batch processing

The data is loaded nightly into Amazon Redshift and is consumed by business analysts

Company wants to move towards near real-time data processing for timely insights

Solution should process the streaming data with minimal effort and operational overhead

Which combination of AWS Services are most cost-effective for this solution

-----

Amazon EC2

Amazon Kinesis Data Firehose
Amazon Kinesis Data Analytics

================

Solutions Architect is designing a new social media application

Application must provide a secure method for uploading profile photos

Each user should be able to upload a profile photo into a shared storage location for one week, after the profile is created

-----

Use Amazon S3 with the default private access policy and generate pre-signed URLs each time a new site profile is created

================

Application relies on messages being sent and received in order

Volume will never exceed 300 transactions per second

Which service should be used

-----

Amazon SQS

================

For security purposes, development team has decided to deploy the EC2 instances in a private subnet

Team plans to use VPC endpoints so that the instances can acess some AWS services securely

Members of the team would like to know about the two AWS services that support Gateway endpoints

As solution architect, which of the following services would you suggest for this requirement

-----

DynamoDb

Amazon S3

================

Solutions Architect is designing a two-tier web application

Application consists of a public facing web tier hosted on Amazon EC2 in public subnets

Database tier consists of Microsoft SQL server running on Amazon EC2 in a private subnet

Security is high priority for company

How should security groups be configured in this situation

-----

Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0

Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier

================

Company has built a serverless application using API Gateway and AWS Lambda

Backend is leveraging an RDS Aurora MySQL database

Web application was initially launched in the Americas and company would now like to expand it to Europe, where a read-only version would be available to improve latency

You plan on deploying the API Gateway and AWS Lambda using CloudFormation, but would like to have a read-only copy of your data in Europe as well

As solutions architect, what you recommend

-----

Use Aurora Read Replicas

================

Engineering team at a retail company is planning to migrate to AWS Cloud from the on-premises data center

Team is evaluating Amazon RDS as the database tier for its flagship application

Team has hired you as an AWS Certified Solutions Architect Associate to advise on Multi-AZ capabilities

Which of following would you identify as correct for RDS Multi-AZ

-----

RDS applies OS updates by performing maintenance on the standby, then promoting the standby to primary and finally performing maintenance on the old primary, which becomes the new standby

Amazon RDS automatically initiates a failover to the standby, in case primary database fails for any reason

================

Company wants to migrate a high performance computing (HPC) application and data from on-premises to the AWS Cloud

Company uses tiered storage on premises with hot high performance parallel storage to support the application during periodic runs of the application, and more economical cold storage to hold the data when the application is not actively running

Which combination of solutions should a solutions architect recommend to support the storage needs of the application

-----

Amazon S3 for cold data storage

Amazon FSx for Lustre for high-performance parallel storage

Amazon FSx for Windows for high performance parallel storage

================

Organization is currently hosting a large amount of frequently accessed data, consisting of key-value pairs and semi-structured documents in their data center

They are planning to move this data to AWS

Which one of following services MOST effectively meets their needs

-----

Amazon DynamoDB

================

Engineering team wants to orchestrate multiple Amazon ECS task types running on EC2 instances that are part of ECS cluster

Output and state data for all tasks need to be stored

Amount of data output by each task is approximately 20 MB, and there could be hundreds of tasks running at a time

As old outputs are archived, the storage size is not expected to exceed 1 TB

As solutions architect, which of the following would you recommend as an optimized solution for high frequency reading and writing

-----

Use Amazon EFS with Provisioned Throughput mode

================

Engineering team at a company is moving the static content from the company's logistics website hosted on EC2 instances to an S3 bucket

Team wants to use a Cloudfront distribution to deliver the static content

Security group used by EC2 instances allows the website to be accessed by a limited set of IP ranges from the company's suppliers

Post-migration to cloudfront, access to the static content should only be allowed from the afore-mentioned IP addresses

Which options would you combine to build a solution to meet these requirements

-----

Create an AWS WAF ACL and use an IP match condition to allow traffic only from those IPs that are allowed in the EC2 security group

Associate this new WAF ACL with the Cloud Front distribution

================

Engineering team at a company is moving the static content from the company's logistic website hosted on EC2 instances to an s3 bucket

Team wants to use a CloudFront distribution to deliver the static content

Security group used by Ec2 instances allows the website to be accessed by a limited set of IP ranges from the company's suppliers

Post-Migration to CloudFront, access to static content should only be allowed from the afore-mentioned IP addresses

Which options would you combine to build a solution to meet these requirements

-----

Create an AWS WAF ACL and use an IP match condition to allow traffic only from those IPs that are allowed in the EC2 security group

Associate this new WAF ACL with the CloudFront distribution

-----

Configure an origin access identity (OAI) and associate it with the CloudFront distribution

Set the permissions in the S3 bucket policy so that only the OAI can read the objects

================

Social media startup uses AWS Cloud to manage its IT infrastructure

Engineering team at the startup wants to perform weekly database roll-overs for a MySQL database server, using a serverless cron job, that typically takes about 5 minutes to execute the database roll over script written in python

The database roll-over will archive the past weeks data from the production database to keep the database small, while keeping its data accessible

As solutions architect, which of the following would you recommend as the MOST cost-efficient and reliable solution

--------

Schedule a weekly EventBridge event cron expression to invoke a lambda function that runs the database roll-over job

================

DevOps team at an IT Company is provisioning a two-tier application in a VPC, with a public subnet and a private subnet

Team wants to use either a NAT instance or a NAT gateway in the public subnet to enable instances in the private subnet to initiate outbound IPv4 traffic to the internet but needs some technical assistance, in terms of configuration options available for the NAT instance and the NAT gateway

---------

NAT instance supports port forwarding

NAT instance can be used as a bastion server

Security Groups can be associated with a NAT instance

================

Company needs to keep user transaction data in Amazon DynamoDB table

Company must retain the data for 7 years

What is MOST operationally efficient solution that meets these requirements

---------

Use AWS Backup to create backup schedules and retention policies for the table

================

A news network uses Amazon S3 to aggregate the raw video footage from its reporting teams across the US

The news network has recently expanded into new geo-graphies in Europe and Asia

Technical teams at the overseas branch offices have reported huge delays in uploading large video files to the destination s3 bucket

Which of the following are most cost-effective options to improve the file upload speed into s3?

---------

Use multi-part uploads for faster file uploads into the destination bucket

Use Amazon s3 transfer accelration to enable faster file uploads into the destination s3 bucket

================

Elastic Load Balancer has marked all the EC2 instances in the target group as unhealthy

When a developer enters the IP address of the Ec2 instances in the web browser, he can access the website

What could be reason that instances are being marked as unhealthy

---------

The route for the health check is misconfigured

The seurity group of the EC2 instance does not allow traffic from the security group of the application load balancer

================

Social Photo-Sharing company uses Amazon s3 to store the images uploaded by users

Images are kept encrypted in s3 by using AWS-KMS and the company manages its own Customer Master Key (CMK) for encryption

Member of DevOps team accidently deleted the CMK a day ago, thereby rendering the user's photo data un-recoverable

You have been contracted by the company to consult them on possible solutions in this crisis

As solutions architect, which of the following steps would you recommend to solve this issue

---------

As the CMK was deleted a day ago, it must be in the 'Pending Deletion' status and hence you can just cancel the CMK deletion and recover the key

================

Company built a food ordering application that captures user data and stores it for future analysis

Application's static front-end is deployed on an Amazon EC2 instance

Front-End application sends the application to the back-end application running on separate EC2 instances

Back-end application then stores the data in Amazon RDS

What should solution architect do to decouple the architecture and make it scalable

---------

Use an Ec2 instance to serve the front-end and write requests to an Amazon SQS Queue

Place the backend instance in an Auto scaling group and scale based on queue depth to process and store the data in Amazon RDS

================

A media streaming company collects real-time data and stores it in a disk-optimized database system

Company is not getting the expected throughput and wants an in-memory database storage solution that performs faster and provides high-availability using data replication

What database should a solution architect recommend

---------

Amazon ElastiCache for Redis

================

PhotoSharing website running on AWS allows users to generate thumbnail images of photos stored in Amazon S3

An Amazon DynamoDB table maintains the location of photos, and thumbnails are easily re-created from the originals if they are accidently deleted

How should the thumbnail images be stored to ensure LOWEST cost

---------

Amazon S3

================

Company helps its customers legally sign highly confidential contracts

To meet strong industry requirements, company must ensure that the signed contracts are encrypted using the company's proprietary algorithm

Company is now migrating to AWS Cloud using AWS S3 and would like you, the solutions architect, to advise them on the encryption scheme to adopt

---------

Client Side Encryption

================

Development team is building an application with front-end and back-end application tiers

Each tier consists of Amazon Ec2 instances behind an ELB classic load balancer

The instances run in AutoScaling groups across multiple availability zones

Network team has allocated the 10.0.0.0/24 address space for this application

Only the front-end load balancer should be exposed to the internet

There are concerns about the limited size of the address space and the ability of each tier to scale

VPC subnet design in each availability zone

---------

One public subnet for the load balancer tier, one public subnet for the front-end tier, and one private subnet for the back-end tier

================

Development team is building an application with front-end and back-end application tiers

Each tier consists of Amazon EC2 instances behind an ELB Classic Load Balancer

The instances run in an AutoScaling group across multiple availability zones

Network team has allocated the 10.0.0.0/24 address space for this application

Only the front-end load balancer should be exposed to the internet

There are concerns about the limited size of the address space and the ability of each tier to scale

What should the VPC subnet design be in each VPC

---------

One public subnet for the load balancer tier, one public subnet for the front-end tier, and one private subnet for the back-end tier

================

Company is storing sensitive user information in an Amazon s3 bucket

Company wants to provide secure access to this bucket from the application tier running on Amazon Ec2 instance inside a VPC

Which steps should solutions architect take to accomplish this

---------

Configure a VPC gateway endpoint for Amazon S3 within the VPC

Create a bucket policy that limits access to only the application tier running in the VPC

================

Silicon Valley based startup has a two-tier architecture using Ec2 instances for its flagship application

The web servers (listening on port 443), which have been assigned security group A, are in public subnets across two availability zones and the MSSQL based database instances (listening on port 1433), which have been assigned security group B, are in two private subnets across two availability zones

DevOps team wants to review the security configurations of the application architecture

As solutions architect, which of the following options would you select as the MOST secure configuration

---------

For Security Group A: Add an inbound rule that allows traffic from all sources on port 443. Add an outbound rule with the destination as the Security Group B on port 1433

For Security Group B: Add an inbound rule that allows traffic only from Security Group A on port 1433

================

You need to migrate a large amount of data into the cloud that you have stored on a hard disk and you decide that the best way to accomplish this is with AWS Import/Export and you mail the hard-disk to AWS

Which of following statement is incorrect in regards to AWS Import/Export

---------

It can export from Amazon Glacier

================

Upon a security review of your AWS account, an AWS consultant has found that a few RDS databases are un-encrypted

As solutions architect, what steps must be taken to encrypt the RDS database

---------

Take a snapshot of the database, copy it as an un-encrypted snapshot, and restore a database from the encrypted snapshot

Terminate the previous database

================

Upon a security review of your AWS account, an AWS consultant has found that a few RDS databases are unencrypted

As Solution Architect, which steps must be taken to encrypt the RDS database

---------

Take a snapshot of the database, copy it as an encrypted snapshot, and restore the database from the encrypted snapshot

Terminate the previous database

================

Company has multiple EC2 instances operating in a private subnet which is part of a custom VPC

These instances are running an image processing application that needs to access images stored on s3

Once each image is processed, the status of the corresponding records needs to be marked as completed in a DynamoDB table

How to go about providing private access to these AWS resources which are not part of this custom VPC

---------

Create a separate gateway endpoint for s3 and dynamodb each

Add two new target entries, for these two gateway endpoints in the route table of the custom VPC

================

Company's website is using an Amazon RDS MySQL Multi-AZ DB instance for its transactional data storage

There are other internal systems that query this database instance to fetch data for internal batch processing

RDS DB instance slows down significantly the internal systems fetch data

This impacts the website's read and write performance, and the users experience slow response time

---------

Add a read-replica to the RDS DB instance and configure the internal systems to query the read replica

================

A web application stores all data in an Amazon RDS Aurora database instance

A solutions architect wants to provide access to the data for a detailed report for the marketing team, but is concerned that the additional load on the database will affect the performance of the web application

How can the report be created without affecting the performane of the application

---------

Provision a new RDS instance as a secondary master

================

IT security consulatancy is working on a solution to protect data stored in s3 from any malicious activity as well as check for any vulnerabilties on EC2 instances

As solutions architect, which of following solutions would you suggest to help address the given requirements

---------

Use Amazon GaurdDuty to monitor any malicious activity on data stored in S3. Use security asssessments provided by Amazon inspector to check for vulnerabilities on EC2 instances

================

Solutions Architecture is designing an architecture for a mobile gaming application

The application is expected to be very popular

Architect wants to prevent the Amazon RDS MySQL database from becoming the bottle-neck due to frequently accessed queries

---------

Amazon ElastiCache in front of RDS MySQL database

================

Solutions Architect is designing a solution where users would be directed to a backup static error page if the primary website is unavailable

Private Website's DNS records are hosted in Amazon Route53 where there domain is pointing to an ALB

Which configuration should the solution architect use to meet the company's needs while minimizing changes and infrastructure overhead

-------

Setup a Route53 active-passive failover configuration

Direct traffic to a static error page hosted within an Amazon S3 bucket when Route53 health checks determine that the ALB endpoint is unhealthy

================

Company is migrating its data center to AWS

As part of migration there is a three tier web application that has strict data at rest encryption requirements

Customer deploys this application on Amazon ECS using Amazon EBS, and now must provide encryption at rest

how can this requirement be met without changing the application

-------

Use encrypted EBS storage volumes with AWS-managed keys

================

As an e-sport tournament hosting company, you have servers that need to scale and be highly available

Therefore you have deployed an ELB with an auto-scaling group (ASG) across three availability zones

When e-sport tournaments are running the servers need to scale quickly

And when tournaments are run, the servers can be idle

As a general rule, you would like to be highly available, have the capacity to scale and optimize your costs

-------

Set the minimum capacity to 2

Use Reserved instances for minimum capacity

================

Reporters at a news agency upload/download video files (about 500 MB each), to/from an s3 bucket as part of their daily work

As the agency has started offices in remote locations, it has resulted in poor latency for uploading and accessing data/to/from s3

Agency wants to continue using a serverless storage solution such as s3 but wants to improve the peformance

As solutions architect, which of the following solutions do you propose to address this issue

-------

Use Amazon CloudFront distribution with origin as the s3 bucket

This would speed up uploads as well as downloads for the video files

================

Your application is hosted by a provider on yourapp.provider.com

You would like to have your users access your application using www.your-domain.com, which you own and manage under Route53

What Route53 record should you create

-------

Create a CNAME record

================

Company's real-time streaming application is running on AWS

As the data is ingested, a job runs on the data and takes 30 minutes to complete

The workload frequently experiences high latency due to large amounts of incoming data

A solutions architect needs to design a scalable and serverless solution to enhance performance

Which combination of steps should a solutions architect take

-------

Setup AWS Fargate with Amazon ECS to process the data

Setup Amazon Kinesis Data Streams to ingest the data

================

An company has setup "AWS Organizations" to manage several departments running their own AWS accounts

The departments operate from different countries and are spread across various AWS Regions

Company wants to setup a consistent resource provisioning process across departments so that each resource follows pre-defined configurations such as using a specific type of EC2 instances

-------

Use AWS CloudFormation stacksets to deploy the same template across AWS accounts and regions

================

Company is planning to use Amazon DynamoDB table for data storage

Company is concerned about cost optimization

The table would not be used on most mornings

In the evenings, the read and write traffic will often be unpredictable

When traffic spike occurs, they will happen very quickly

What should a solutions architect recommend

--------

create a DynamoDb table in on-demand capacity mode

================

Product team at a startup has figured out a market need to support both stateful and stateless client-server communications via the APIs developed using its platform

You have been hired by the startup as a solutions architect to build a solution to fulfill this market need using AWS API Gateway

Which of following is correct

-------

API Gateway creates RESTful APIs that enable stateless client-server communication and API Gateway also creates WebSocket APIs that adhere to the websocket protocol, 
which enables stateful, full-duplex communication between client and server

================

A photo sharing service publishes a collection of of beautiful mountain images, every month, that aggregate over 50 GB in size and downloaded all around the world

Content is currently hosted on EFS and distributed by ELB and Amazon EC2 instances

Website is experiencing high load each month and very high network costs

As solutions architect, what can you recommend that won't force an application re-factor and reduce network costs and EC2 load drastically

-------

Create a CloudFront distribution

================

E-Commerce company is looking for high-availability, as it plans to migrate its flagship application to a fleet of Amazon EC2 instances

Solution should allow for content based routing as part of the architecture

As solutions architect, which of following will you suggest for the company

-------

Use an Application load balancer for distributing traffic to the EC2 instances spread across different avaialbility zones

Configure Auto Scaling group to mask any failure of an instance

================

You have multiple AWS accounts within a single AWS region managed by AWS Organizations

You would like to ensure that all EC2 instances in all these accounts can communicate privately

Which of following solutions would provide cheapest cost

-------

Create a VPC in an account and share one or more of its subnets with the other accounts using Resource Access Manager

================

Company is running a popular social media website

Website gives users the ability to upload images to share with other users

Company wants to make sure that images do not contain in-appropriate content

Company needs a solution that minimizes development effort

What should solution architect do to meet these requirements

-------

Use Amazon Rekognition, to detect in-appropriate content

Use human review for low-confidence predictions

================

Application maintenance team at company has noticed that production application is very slow when the business reports are run on the RDS database

Reports fetch a large amount of data, and have complex queries with multiple joins, spanning across multiple business-critical core tables, CPU, memory and storage metrics are around 50% of total capacity

Can you recommend an improved and cost-effective way of generating the business reports while keep the production application un-affected

-------

Create a real replica and connect the report generation tool/application to it

================

Financial services company wants to move windows file server clusters out of their data centers

They are looking for cloud file storage offerings that provide full windows compatability

Can you identify the AWS Storage services that provide highly reliable file storage that is accessible over the industry standard Server Message Block (SMB) protcol compatible with Windows Systems

-------

Amazon FSx for Windows file server

File Gateway configuration of AWS Storage Gateway


================

Application runs on Amazon EC2 instances in private subnets

Application needs to access an Amazon DynamoDb table

What is the most secure way to acecss the table while ensuring that the traffic doesn't leave the AWS network

--------

Use a NAT instnace in a private subnet

================

You would like to migrate an AWS account from an AWS Organizaion A to an AWS Organization B

What are steps to do it

-------

Remove the member account from the old organization

Send an invite to the member account from the new Organization

Accept the invite to the new Organization from the member account

================

A DevOps engineer at an IT company just upgraded an EC2 instance type from t2.nano to u-12tbl.metal 

How would you categorize this update

------

This is a scale up example of vertical scalability

================

Test # 5
-----------

Company's web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes

Company is looking to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation and durability (ACID)

What should solutions architect do to meet these requirements

------

Launch the application on EC2 instances in each availability zone. Attach EBS volumes to each EC2 instance

=============

Company currently operates a web application backed by Amazon RDS MySQL database

It has automated backups that are run daily and not encrypted

Security audit requires future backups to be encrypted and the un-encrypted backups to be destroyed

What should be done to enable encryption for future backups

------

Create a snapshot of the database

Copy it to an encrypted snapshot

Restore the database from the encrypted snapshot

=============

Firm has implemented a multi-tiered networking structure within the VPC with two public and two private subnets

The public subnets are used to deploy the Application Load Balancers, while the two private subnets are used to deploy the application on an Amazon Ec2 instance

Development team wants the EC2 instances to have access to the internet

Solution has to be fully managed by AWS and needs to work over IPv4

------

NAT Gateways deployed in your public subnet

=============

Solution Architect is designing a two-tier web application

Application consists of a web-tier hosted on Amazon EC2 in public subnets

Database tier consists of Microsoft SQL server running on Amazon EC2 in a private subnet

Security is a high priority for the company

How should security groups be configured

------

Configure the security group for the web tier to allow inbound traffic on port 443 from 0.0.0.0/0

Configure the security group for the web tier to allow outbound traffic on port 443 from 0.0.0.0/0

------

Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier

=============

Company has been storing analytics data in an Amazon RDS instnace for the last few years

Company asked a solutions architect to find a solution that allows users to access this data using an API

The expectation is that application will experience periods of inactivity but could receive bursts of traffic within seconds

Which solution should the solution architect suggest

------

Setup an Amazon API Gateway and uses AWS Lambda functions

=============

The infrastructure team at a company maintains 5 different VPCs for resource isolation (VPC A, B, C, D, E)

Due to changed organizational structure, the team wants to inter-connect all VPCs together

To facilitate this, team has setup VPC peering connection between VPC A and all other VPCs in a hub and spoke model with VPC A at the center

However, team has still failed to establish connectivity between all VPCs

As a solutions architect, which of following would you recommend as the MOST resource-efficient and scalable solution

--------

Use a transit gateway to interconnect the VPCs

=============

Cyber security company uses a fleet of EC2 instances to run a proprietary application

Infrastructure maintenance group at the company wants to be notified via an email whenever the CPU utilization for any of the EC2 instances breaches a certain threshold

Which of following services would you use for building a solution with the least amount of development effort

--------

Amazon CloudWatch

Amazon SNS

=============

Web application is deployed in AWS Cloud

It consists of a two-tier architecture that includes a web layer and a database layer

Web server is vulnerable to cross-site scripting (XSS) attacks

What should solutions architect do to remediate the vulnerability

--------

Create an application load balancer

Put the web layer behind the load balancer and enable AWS WAF

=============

New DevOps engineer has joined a large financial services company recently

As part of this on-boarding, the IT deparment is conducting a review of the checklists for the tasks related to AWS Identity and Access Management

As a solutions architect, which best practise would you recommend

--------

Configure AWS CloudTrail to log all IAM actions


Enable MFA for privileged users

=============

New Devops engineer has joined a large financial services company

As part of his on-boarding, IT department is conducting a review of the checklist for tasks related to AWS Identity and Access Management

As solutions architect, which best practises would you recommend

--------

Configure AWS CloudTrail to log all IAM actions

Enable MFA for privileged users

=============

DevOps engineer has joined a large financial services company recently

As part of his onboardings, the IT department is conducting a review of the checklists for tasks related to AWS Identity and Access Management

As solutions architect, which best practices would you recommend

--------

Configure AWS Cloud Trail to log all IAM actions

Enable MFA for privileged users

=============

Medical devices company uses s3 buckets to store critical data

Hundreds of buckets are used to keep the data segregated and well organized

Recently the development team noticed that the life-cycle policies on the s3 bucket have not been applied optimially, resulting in higher costs

As Solutions Architect, can you recommend a solution to reduce storage costs on s3 while keeping the IT team's involvement to a minimum

--------

Use S3 intelligent tiering storage class to optimize the S3 storage costs

=============

Built an application that is deployed with an ELB and an Auto Scaling Group

As solutions architect, you have configured aggresive cloudwatch alarms, making your auto-scaling group scale in and out very quickly, renewing your fleet of Amazon EC2 instances on a daily basis

A production bug appeared two days ago, but the team is unable to SSH into the instance to debug the issue, because the instance has already been terminated by the ASG

Log files are saved on the EC2 instances

how will you resolve the issue and make sure it doesn't happen again

--------

Install a CloudWatch logs agent on the EC2 instances to send logs to CloudWatch

=============

An IT company wants to optimize the costs incurred on its fleet of 100 Ec2 instances for the next one year

Based on historical analyses, the engineering team observed that 70 of these instances handle the compute services of its flagship application and need to be always available

Other 30 instances are used to handle batch jobs that can afford a delay in processing

As solutions architect, which of the following would you recommend as MOST cost-optimal solution

--------

Purchase 70 reserved instances and 30 spot instances

=============

An IT Company has an Access and Control Management Application that uses Amazon RDS for MySQL but is running into performance issues despite using read replicas

Company has hired you as a Solutions Architect to address these performance related challenges without moving away from the underlying relational database schema

Company has branch offices across the world, and it needs the solution to work on global scale

Which of following is most cost-effective and high-performance solution

--------

Use Amazon Aurora Global Database to enable fast local reads with low latency in each region

=============

Deploying a critical monolith application that must be deployed on a single web server, as it hasn't been created to work in distributed mode

You want to make sure your setup can automatically recover from the failure of an AZ

Which of the following steps should be combined to form the most cost-efficient solution

--------

Create an Elastic IP and use the EC2 user-data script to attach it

Create an Auto-Scaling group that spans across 2 AZs, which min=1, max=1, desired=1

Assign an EC2 instance role to perform the necessary API calls

=============

Big data consulting firm is working on a client engagement where the ETL workloads are currently handled via a Hadoop cluster deployed in the on-premises data center

Clients want to migrate their ETL workloads to AWS Cloud

AWS Cloud Solution needs to be highly available with about 50 EC2 instances per availability zone

As a solutions architect, which of the following EC2 placement groups would you recommend handling the distributed ETL workload

--------

Partition placement group

=============

Company runs an application using Amazon ECS

Application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3

How can Solutions Architect ensure that the application to access Amazon S3

--------

Update the s3 role in AWS IAM to allow read/write access from Amazon ECS, and then re-launch the container

=============

IT Consultant is helping the owner of a medium sized business setup an AWS account

What are the security recommendations he must follow while creating the AWS account root user

--------

Enable Multi-Factor authentication (MFA) for the AWS account root user account

Create a strong password for the AWS account root user

=============

Solutions Architect is designing storage for high performance computing environment based on Amazon Linux

Workload stores and processes a large amount of engineering drawings that require shared storage and heavy computing

Which storage option would be the optimal solution

--------

Amazon FSx for lustre

=============

Research Group needs a fleet of EC2 instances for a specialized task that must deliver high random I/O performance

Each instance in the fleet would have access to a data set, that is replicated across the instance

Because of the resilient application architecture, the specialized task would continue to be processed even if any instance goes down, as the underlying application architecture, would ensure the replacement instance has access to the required dataset

which of following option is MOST cost-optimal and resource-efficient solution to build this fleet of Ec2 instances

--------

Use Instance store based EC2 instances

=============

Survey company has gathered data for several years from areas in the United States

Company hosts the data in an Amazon S3 bucket that is 3 TB in size and growing

Company has started to share the data with a European marketing firm that has s3 bucket

Company wants to ensure that its data transfer costs remain as low as possible

Which solution will meet these requirements

--------

Configure s3 cross-region replication from the company's s3 bucket to one of the marketing firms' s3 bucket

=============

Solutions Architect is creating an application running in an Amazon VPC that needs to access AWS System Manager Parameter store

Network security rules prohibit any route table entry with a 0.0.0.0/0 destination

What infrastructure addition would allow access to the AWS service while meeting the requirements

--------

AWS PrivateLink

=============

You would like to use snowball to move on-premises backups into a long term archival tier in AWS

Which solution provides the most cost savings

--------

Create a Snowball job and target an s3 bucket

Create a life-cycle policy to transition this data to Glacier deep archive on the same day

=============

IT company working on a client project to build a supply chain management application

Web-tier of application runs on an EC2 instance and the database tier is on an Amazon RDS MySQL

For beta testing, all the resources are currently deployed in a single availability zone

Development team wants to improve application availability before the go-live

Given that all end users of the web application would be located in the US, which of following would be MOST resource-efficient solution

--------

Deploy the web-tier EC2 instances in two availability zones, behind an elastic load balancer

Deploy the Amazon RDS MySQL database in Multi-AZ configuration

=============

As a solutions architect, you would like to completely secure the communication between your Cloudfront distribution and your s3 bucket which contains the static files for your website

Users should not be able to access the s3 bucket through cloudfront and not directly

What do you recommend

--------

Create an origin access identity (OAI) and update the S3 bucket policy

=============

Development team has configured an Elastic Load Balancer for host-based routing

Idea is to support multiple sub-domains and different top-level domains

The rule *.example.com matches which of the following

--------

*test.example.com

=============

Engineering team at a startup is evaluating the most optimal block storage volume type for the EC2 instances hosting its flagship application

The storage volume should support very low latency but it does not need to persist the data when the instance terminates

As solutions architect, you have proposed using instance store volumes to meet these requirements

Which of the following would you identify as key characteristic of the instance store volumes

--------

You can't detach an instance store volume from one instance and attach it to a different instance

If you create an AMI from an instance, the data on its instance store volumes isn't preserved


=============

Software engineering intern at an e-commerce company is documenting the process flow to provision Ec2 instances via the Amazon Ec2 API

These instances are to be used for an internal application that processes HR payroll data

He wants to highlight those volume types that cannot be used as a boot volume

Can you help the intern by identifying those storage volume types that CANNOT be used as boot volumes while creating the instances

--------

Cold HDD (sc1)

Throughput optimized HDD (st1)

=============

An e-commerce application uses a relational database that runs several queries that perform joins on multiple tables

Development team has found that these queries are slow and expensive, therefore these are a good candidate for caching

Applicant needs to use a caching service that supports multi-threading

As solutions architect, which of following servics would you recommend for given use case

--------

Amazon ElastiCache for Memcached

=============

Solutions architect is designing the architecture for a web application that will be hosted on AWS

Internet users will access the application using HTTP and HTTPS

How should the Solution Architect design the traffic control requirements

--------

Allow inbound ports for HTTP and HTTPS in the security group used by the web servers

=============

A gaming company uses Application Load Balancers (ALBs) in front of Amazon EC2 instances for different servics and micro-services

Architecture has now become complex with too many ALBs in multiple AWS regions

Security updates, firewall configurations, and traffic routing logic have become complex with too many IP addresses and configurations

Company is looking at an easy and effective way to bring down the number of IP addresses allowed by the firewall and easily manage the entire network infrastructure

Which of these options represent an appropriate solution for this requirement

--------

Launch AWS Global Accelrator and create endpoints for all the Regions

Register the ALBs for each region to the corresponding endpoints

=============

Company needs a massive PostgreSQL database and the engineering team would like to retain control over managing the patches, version upgrades for the database, and consistent performance with high IOPS

Team wants to install the database on an EC2 instance with the optimal storage type on the attached EBS volume

As solutions architect, which of the following configurations would you suggest to the engineering team

--------

Amazon EC2 with EBS volume of Provisioned IOPS SSD (io1) type

=============

An engineering team wants to examine the feasibility of the user data feature of Amazon EC2 for an upcoming project

which of the following are true about the EC2 user data configurations

--------

By default, scripts entered as user data are executed with root user privilges

By default, user data runs only during the boot cycle when you first launch an instance

=============

An application running on AWS uses an Amazon Aurora Multi-AZ deployment for its database

When evaluating performance metrics, a solutions architect discovered that the database reads are causing high I/O and adding latency to the write requests against the database

What should solutions architect do to separate the read requests from the write requests

--------

Create  read replica and modify the application to use the appropriate endpoint

=============

Company hosts its product information webspages on AWS

Existing solution uses multiple Amazon EC2 instances, behind an application load balancer in an Auto Scaling group

Website also uses a custom DNS name and communicates with HTTPS only using a dedicated SSL certificate

Company is planning a new product launch and wants to be sure that users from around the world have the best possible experience on the new website

What should solutions architect do to meet these requirements

--------

Redesign the application to use Amazon CloudFront

=============

One of the biggest football leagues in Europe has granted the distribution rights for live streaming its matches in the US to a silicon valley based streaming services company

As per the terms of distribution, company must make sure that only users from the US are able to live stream the matches on their platform

Users from other countries in the world, must be denied access to these live-streamed matches

Which of the following options would allow the company to enforce these streaming restrictions

-----

Use Route53 based geo-routing policy to restrict distribution of content to only the locations in which you have distribution rights

Use georestriction to prevent users in specific geographic locations from accessing content that you are distributing through a Cloud Front distribution

=============

Company has recently created a new department to handle their services workload

An IT team has been asked to create a custom VPC to isolate the resources created in this new department

They have setup the public subnet and Internet Gateway

However, they are not able to ping the Amazon EC2 instances, with Elatic IP launched in the newly created VPC

As Solutions Architect, the team has requested your help

How will you trouble shoot this scenario

-----

Check if the route table is configured with IGW

Check if the security groups allow ping from the resource

=============

An IT company has a large number of clients opting to build their APIs by using Docker containers

To facilitate the hosting of these containers, the company is looking at various orchestration services available with AWS

As solutions architect, which of the following solutions will you suggest

-----

Use Amazon EKS with AWS Fargate for serverless orchestration of the containerized services

Use Amazon ECS with AWS Fargate for serverless orchestration of the containerized services

=============

Test # 10 
-----------

You would like to congratulate your developers on important milestones, such as --their first paid contract. All the contracts are stored in the dynamodb. Which dynamodb feature can you use to implement this functionality such that there is least delay in sending automatic notifications - DynamoDB streams + Lambda

==========

An HTTP application is deployed on an AutoScaling group, is accessible from an application load balancer that provides HTTPS termination, and accesses a PostgreSQL database managed by RDS. How to configure security groups - The security group of the ALB, should have an inbound rule from anywhere on port 443. The security group of RDS should have an inbound rule from the security group of the EC2 instance in the ASG on port 5432. The security group of the EC2 instances should have an inbound rule from the securiy group of the ALB on port 80

======

Solution Architect is designing the storage layer for a production relational database. Database would run on EC2. Database is accessed by an application that performs insensitive read and writes, so the database requires the LOWEST random I/O latency. which data storage method - Stripe data across multiple Amazon EBS volumes using RAID 0

======


Current solution design uses a single s3 bucket in us-east-1 region with versioning enabled to store the dataset. Company's disaster recovery policy states that all data multiple AWS Regions. How solution architect would design s3 solution - Create an additional s3 bucket with versioning in another Region and configure cross-Region replication

=========

Company has application servers in the public subnet that connect to the RDS instances in the private subnet. For regular maitenance RDS instances need patch fixes that need to be downloaded from the internet. Considering that company uses only IPv4 addressing and is looking for a fully managed service, which of following would you suggest as an optimal solution - Configure a NAT gateway in the public subnet of the VPC

===================

Company wants to improve gaming application by adding a leader board that uses a complex proprietary algorithm based on participating user's performance metrics to identify top users on real time basis. Leaderboard would be accessed by millions of users simulataneously. Leaderboard would be accessed by millions of users simultaneously. Which following options support the case for using ElastiCache - Use Elasticache to improve latency and throughput for read heavy application workloads. Use ElastiCache to improve the performance of compute-intensive workloads.

=======

Company hosts a static website within Amazon S3 bucket. Solution architect needs to ensure that data can be recovered in case of accidental deletion. Which action will accomplish this - Enable S3 versioning

=======

Solution Architect must select the storage type for a big data application that requires very high sequential I/O. Data must persist if the instance is stopped. Which storage types provide best fit at the lowest cost for the application - An Amazon EBS throughput optimized HDD volume

=======

Flagship application for a gaming company connects to an Amazon Aurora database and the entire technology stack is currently deployed in United States. Now the company has plans to expand to europe and asia for its operations. It needs the games table to be accessible globally but needs the users and games_played tables to be regional only - UseAmazon Aurora Global database for the games table and use Amazon Aurora for the users and games_played table

=======

Company is migrating from an on-premises infrastructure to the AWS Cloud. One of the company's application stores files on a Windows file server farm that uses Distributed File System Replication (DFSR) to keep data in sync. Solutions architect needs to replace the file server farm. Which server should the solutions architect use - Amazon FSx

=======











-----
when to use a particular service rather than another

Credential storage
A single store for configuration and secrets - Parameters store
Dedicated secrets store with with life-cycle managment - Secrets manager

Knowledge Areas : 


Design for new solutions
Continuous improvement for existing solutions
Design solutions for organizational complexity
Accelrate workload migration and modernization
Migration planning




- 3 Hours for Religious Identification





